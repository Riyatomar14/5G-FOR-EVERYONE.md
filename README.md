# 5G-FOR-EVERYONE
In this we discuss 8 modules about 5G .
## 1 MODULE: wireless communications and cellular networks

# > wireless signal basic
first we will understand what factors ultimately impact the speed of the data rate that you get on your phone. Now, wireless communication allows transfer of information between a transmitter and a receiver without a physical medium. Emphasis on that clause, "without a physical medium." That is because many other forms of communications that we engage in on a daily basis require some or the other form of a medium. For example, a landline phone, if you have one at home, the signal for the landline phone comes over a wire, hence the name landline. Even our modern-day internet connection is actually delivered to your home using some form of an internet cable. Even when we speak with each other, our voice requires an explicit medium such as air or other solid medium to go from one point to another. In contrast to all of those examples, wireless communication does not need a physical medium. It can travel just as well in a vacuum space, so to speak. 

a typical wireless communication system has four fundamental components; A transmitter, a receiver, a wireless signal, and a fourth imaginary entity that is called a wireless channel.What is a transmitter?The entity that is looking to transmit some data to the other end over a wireless medium, that will be called the transmitter. On the other hand, the entity that is looking to receive that data will be called the receiver. In modern-day communication systems, most devices have the capability to act as both the transmitter as well as the receiver, either at the same time or at different points in time. As we all know, our antennas are also an integral part of any transmitter or receiver, because that is what helps you send or receive wireless signals. That brings us to the other two entities in a typical wireless system namely wireless signals are also called radio-frequency signals or RF Signals, and the imaginary channel over which those wireless signals go from one point to another called either the wireless channel or the radio channel. 

# > Radio Signal Properties, Carrier Waves and Modulation

all wireless signals travel at the speed of light, which is approximately 300,000 kilometers per second or about 186,000 miles per second and periodic in nature. In that, they show a certain pattern and that pattern repeats as a function of time. That fundamental periodic nature leads us to two basic attributes of radio frequency signals, namely frequency and wavelength.Frequency is the number of repetitions that the periodic electromagnetic signal undergoes in a given second, and the frequency is measured in the unit of hertz. Wavelength, on the other hand, is the distance that periodic wireless signal travels during one cycle or one periodicity, and because it is a measure of distance, it is mostly measured in meters or millimeters equivalently.If you multiply frequency and wavelength of a wireless radio signal, you get the speed of that radio signal, which as we know now is the universal constant, that is, the speed of light. Frequency and wavelength of a wireless signal are inversely related. The relational constant being the universal constant, the speed of light. The radio signals that are used for wireless communications happen to range from somewhere between 3 kilohertz and 300 gigahertz. This would probably be the lowest frequency that may be used for wireless communication, and this may be somewhat the highest frequency. Traditionally, this particular frequency range has been called the radio frequency signal range. That is the fundamental reason why wireless signals are interchangeably also called radio signals or radio frequency or RF signals because the frequency of those wireless signals happens to lie between the range specified by the traditional radio frequency range. a wireless or radio signal has two components, an electrical component, and a magnetic component, hence the name electromagnetic signals.RF signals are used as the so-called vehicle for information transfer because they carry your information from the transmitter to the receiver. These periodic RF signals or wireless signals are also known as carrier waves because they carry the information from one end to the other.Modulation is a process by which we impress or impose information onto the carrier wave for transmission. Modulation at the high level is about carefully changing some of the specific attributes of the radio-frequency signal. Two of those attributes, we have already learned about frequency and wavelength.Now, depending upon what type of information you originally wanted to send, either analog or digital, the corresponding modulation will be called analog modulation or digital modulation. It impresses the information onto the outgoing carrier wave in the process of modulation. At the receiver, however, the other end of wireless communication, we need to extract that information from the incoming carrier wave. That process of extraction is called demodulation. Demodulation is the process of recovering the data that has been impressed upon the carrier wave by the transmitter. What is the word modem? Well, it is an amalgamation of two words, modulation, and demodulation. That's why the word modem. That is because when the wireless device acts as a transmitter, it uses the modulation part of its functionality. Whereas when it acts as a receiver, it uses the demodulation aspects of its functionality. Because it can perform both the functionalities, that particular device is called modem.

# > What Happens During a Phone Conversation: Wireless Transmission and Reception

let's say that you have called your mom and the phone rang. She picked up the phone and you greeted her saying, hi, mom. When you say those words at a high level, that sound goes to the modulator inside your phone among other things. And as we know, modulator has the job of impressing that information, which is our greeting here on to a carrier wave. So modulator impresses that information onto a carrier wave. But the phone's internally work on a default frequency, which may be different from the frequency assigned to your phone by the network operator or the cellular provider. So your phone intrinsically converts that carrier wave into the specific frequency assigned to it by other network operator which has got upconversion. And once the signal is at the desired frequency, it undergoes a power amplification. 
Now, that radio frequency signal travels over the air and when it travels over the air it faces certain impediments. The most important and most significant of which is called attenuation or path loss or transmission loss. Let's say that after a certain amount of transmission loss, that signal reaches your mother's phone. So the incoming signal is also amplified inside your mother's phone. And because the transmitter phone had to upconvert in frequency the receiver's phone, we need to downconvert in frequency to convert that carrier away frequency into the default frequency that your phone can understand. And just like the transmitter's phone had to use the modulator functionality, the receiver's phone will need to use the demoderator functionality in order to extract the information that has been impressed upon the incoming carrier wave. And when your mother's phone is able to demodulate that information, that greeting is then converted into voice and that is the same greeting you sent her, hi, mom. And this is how when you talk to someone over phone they get to hear your voice and you in turn get to hear their voice. the signal from your phone actually goes over to a cell tower, technically known as a base station. So this cell tower is something that is deployed by your cellular network operator, towers that we see all around us. So the signal from your phone doesn't directly go to your mother's phone, it rather goes to a cell tower deployed by the network operator. The operator might perform some additional processing on that signal and then that signal is transmitted by the network operator cell tower to your mother's phone. So, in reality, this communication exchange is mediated by the cell tower and the signal doesn't directly go from one phone to another.called noise and interference. Now, the technical description of noise and interference and their significance is coming up shortly. noise and interference have the potential to change the appearance of the wireless signal when it actually reaches the receiver. And that has a couple of profound implications that will learn about shortly.

# > Noise and Interference

both noise and interference are forms of unwanted energy in addition to your intended energy. But noise is natural in sources, it is always present. You cannot minimize that beneath a certain threshold whereas interference is deliberate in nature and can be mitigated by careful planning of the frequency use by different entities in the network. For example, if you could institute certain rules saying that this transmitter cannot transmit at the same frequency or cannot transmit at the same time as transmitter 1, then you can tell that the interference shown here will be eliminated or greatly reduced if the transmitters follow those basic rules. It is possible to mitigate or altogether eliminate interference but not so much with noise. noise and interference play such a crucial role in a typical wireless system. The fundamental one is called SNR, or signal-to-noise ratio.in case of little noise or interference, the SNR or SINR may be very high. That is the point that a wireless system aims to operate at. Whereas if you gradually increase the amount of noise or interference relative to the strength of the desired signal, you can tell that mathematically, SNR or SINR will begin to gradually drop.

# > Radio Spectrum

Radio spectrum essentially is just the range of radio frequencies over which a wireless communication takes place, for a specific purpose. Just like how your car needs certain space on the road to be driven, any wireless or electromagnetic signal needs a certain space, so to speak, in the frequency domain for it to go from one point to another. That place in the frequency domain is nothing but radio spectrum. Now, frequencies or the radio spectrum that can be allocated for different purposes as we saw, can range from three kilohertz at the lowest to 300 gigahertz and the highest, which is our range of radio frequencies, as we established earlier. Specifically for mobile phones, it is still a broad range that those phones can use depending upon their generation. For example, some of the earliest mobile phones are operated in frequencies as low as 450 megahertz., whereas some of the intermediate generations, such as for 4G LTE, operate in frequencies that are as high as 2.6 gigahertz, somewhere over here. The upcoming technology 5G can operate in frequencies that are as high as 39 gigahertz. this frequency of 39 gigahertz has a very special significance. It is near and dear to the hearts of all the wireless engineers these days. In technical terms, that frequency is called millimeter wave. But apart from cellular phones, as you can see, there are many other purposes that the radio spectrum can be used for. For example, your citizen's band radio would use frequencies around 10 - 20 kilohertz. Your AM radio would use frequencies around, between one and two megahertz. Your FM radio would be somewhere around 100 megahertz, and your satellite TV or satellite radio would be somewhere around 25 gigahertz. Cell phones or mobile phones aren't the only wireless entities that utilize the radio spectrum, they are just one subset of the entire wireless ecosystem. There are many other services and devices that need to access radio spectrum, and at such those services are spread out across the entire radio spectrum.who makes these decisions? Who decided that 5G will operate over here, and FM radio will operate over here.In case of United States, that government regulatory entity is the FCC or Federal Communications Commission. Nearly any country has their own equivalent of FCC. The FCC equivalent has the primary responsibility to allocate and apportion frequency spectrum to different services depending upon the service needs and the needs of the propagation environment. For example, it was the FCC who decided, for example, that AM radio would operate here, and FM radio would operate here, and mobile communications would get these type of frequency ranges. It is the local regulatory authority that determines what spectrum will be used by what service, for what purpose.

# >Radio Channel and Bandwidth

When your phone transmits or receives a signal, it only uses a small subset or a sliver of the frequency spectrum. And that limited range of frequencies over which a wireless device, exchanges wireless or radio signals, it's called its frequency channel. And the word of the frequency channel currently being used by a wireless device, it's called the channel bandwidth. there are roughly two classifications of a wireless channel, narrowband and wideband. In narrowband channel, as the definition says, occupies just a small amount of radio spectrum, on the order of a few kilohertz or a few thousand hertz. Whereas a wideband channel, occupies a large amount of radio spectrum relatively higher than the narrowband channel, on the order of few megahertz or millions of hertz. And as the logic might go, a narrow band channel, given everything else equal, will help you send limited amount of data. And a wideband channel on the other hand, can help you send a large amount of data. so, you think that every channel will be wide band channel but no .A corollary of availability is because spectrum is a scarce resource. It begins to get more and more expensive as you begin to buy more and more spectrum. So if you had to buy a wideband channel for every user, your system will be extremely expensive because spectrum is inherently a scarce and expensive commodity. So availability and costs are a couple of reasons for which not every channel can be a wideband channel. But beyond that, there is one more reason, for which not every user can get a wideband channel, and that is precisely what we are going to look at next.

# > Sharing the Radio Channel

can different users share this data pipe or the wireless channel? And the answer to that question is absolutely yes. There are defined algorithms that allow sharing of the radio channel and that translates to a concept of multiple access. Meaning that when multiple users are trying to access the same wireless channel at the same time, that concept is called multiple access and that is not very difficult to understand. For example, consider that there is only one user at a given point in time. So, the entire pipe for the entire wireless channel will be available to that user and that will be equivalent of a wideband channel. But now, consider that there are three more users trying to utilize the same wireless channel. So, in the interest of fairness or equity, all the users will get a certain sliver of that wireless channel depending upon their application requirements. And the wireless system will have to divide the available resources, the number of users that are trying to access the system at the same time. And that is what makes shared data channel like a shared a pipe. And there are trade offs to be achieved on this front, just like there are tradeoffs with many other engineering problems. In that, because the users now have to share the wireless channel stands to reason that each of them will get fewer wireless resources than they were if they were the only user trying to access the wireless channel. So that is a slight disadvantage, but a big advantage in favor of multiple access is that you don't have to allocate or buy individual dedicated channels for individual users. Which would be prohibitively expensive, given how scarce and costly the frequency spectrum is getting these days. So, multiple access allows us to achieve that desirable trade off between the cost of the frequency spectrum you need to operate your system. We're says the amount of resources individual users get which ultimately determines the speed or the data rate that they will get on their phones. a technology called CDMA that was a technology pioneered by qualcomm in the mid nineties. The MA in CDMA stands for multiple access, and what does multiple access mean? In general, just like modulation entails carefully changing certain attributes of the wireless signal you are trying to send out multiple access involves carefully leveraging some of the attributes of the wireless channel. Wireless channel, as we'll see, has different attributes, such as frequency time, etc. And if different users can carefully leverage some of those attributes that constitutes multiple access. So, these are the couple of quick notes about multiple access, which is a fundamental concept that allows multiple users to share the scarce and limited frequency resources, ie a wireless channel.

# > Two Ways of Sharing the Spectrum: FDD & TDD

Now all these users were users like your phones or your tablets. But what about the cell tower or the base station as we have talked about earlier, does it utilize the same resources as your phone, or does it utilize different resources from your phone? Well, the answer is, it depends. That leads us to two distinct variants of wireless communication called FDD and TDD, which respectively stand for frequency division duplexing and time division duplexing.they are simply two ways to share the limited and expensive spectrum. But in this particular context, they aren't necessarily the way to share the spectrum among other users on the phone. Rather, they are other ways to share spectrum between the cell tower or the base station and the rest of the phones.FDD, it stands for frequency division duplexing, entails and requires rather a pair of radio channels for simultaneous two-way communication. For example, if you have abundant frequency spectrum, you could allocate one channel on which your cell tower would transmit. You could allocate a different independent frequency channel on which your phone would transmit. In technical parlance, now the transmissions that are sent by the base station or the cell tower are called downlink and the transmissions that are sent by your phone are called uplink. It is called so because traditionally base station is located at a larger height, it is taller than normal users, and hence, the signal from the base station comes down to you. Whereas, when your phone transmits a signal to a base station because base station is located at a higher level, the phone signal has to travel upwards, so to speak. That's why the name downlink, whereas this is uplink. In FDD, your system is rich enough to buy two separate channels. One channel, wherein only the base station will transmit and the phone will only receive on the channel. Whereas on the second uplink channel, it is only the phone that is allowed to transmit, and the base station will only need to receive on that channel. There is separation of responsibilities in the frequency domain, so to speak. There are, as always, pros and cons. The pros are that, as the first point mentions here, because those two are independent channels, it allows for simultaneous two-way communications. In that the base station can transmit something to the phone on the downlink. At the same time while the phone is listening, it can also try to send some information to the same base station on the uplink, thus allow for two-way communication. However, the basic disadvantage of this FDD mechanism is that you have to have enough budget in order to buy two separate frequency channels. Not only that, your local regulatory authorities have to have abundance spectrum available in order to allocate two independent channels for your system. One for downlink, one for uplink. TDD, also known as time division duplexing. As you may have guessed, it is called so because it leverages the time aspect of the wireless channel. The hallmark of a TDD system is that, unlike an FDD system, a TDD system has access to only one frequency channel. There are no two frequency channels anymore. Both the base station and your phones have to operate on the same frequency channel. Single radio channel is the basic characteristic of a TDD system. But if you have to accommodate transmissions in two different directions on the same channel, how can you make that happen? Well, that is where leveraging the time attribute of the channel comes into picture. For example, on the same channel, you might have the base station transmits from, let's say, time t1 to t2. From time t2 to t3, you will open that channel up for the other direction of transmission, that is uplink. Once again, if the operating data demand has been satisfied, you can open the same channel back to the base station from t3 to t4. Once again, from t4 to t5, you can let the phone transmit. Because you have just one frequency channel, you effectively have to alternate between the downlink and uplink on the base station transmissions and the transmission by your phone.a TDD system, given everything else equal, will be cheaper to implement as compared to an FDD system. 

# > Factors Affecting Data Rate

First of which is how many bars does your phone have, which ultimately translates to how good is your connection. This would be the equivalent of the quality of the rules. If you have more bars, it naturally means that your signal is of better quality. And that means that your SNR or signal to noise ratio, Higher the SNR given everything else equal, higher data rate you will be able to achieve. The second is how wide is my channel and how crowded it is. if a channel is wide, it is said to have higher channel capacity. if there are many users trying to access the same wireless channel at the same time, the channel be loaded with users, so to speak, and that is what we call network load. So the width of your channel and the crowd on that channel, meaning network load are also a couple of important factors that impact your data rate. The third factor is how frequently and how efficiently can the phone use this available channel? If the phone can utilize the channel more frequently, your phone will be able to get higher data rates. And if your phone, whenever it gets to utilize the wireless channel can utilize that channel with more efficiency. higher the spectral efficiency, higher the data rate or higher the speed will be because you are using the existing resources with more efficiency. Now, spectral efficiency,If you could operate your system more efficiently, you can utilize the same existing amount of resources more efficiently and improve your performance, which in this context would be your speed or your data rate, technically also known as throughput. And given that these three factors are closely impact throughput and throughput ultimately impacts user experience and customer satisfaction. Wireless network operators spend a good deal of time, money, and other resources in order to optimize all these factors, i.e., maximize the SNR, maximize channel capacity but minimize network load, and maximize spectral efficiency in order to maximize user experience and customer satisfaction.

# > The Cellular Concept

if you compare a modern cellular network to a legacy wireless network such as FM radio, we'll notice that FM radio and a cellular network  in entirely different manner. An FM radio usually broadcasts its signal from just one common tower, let's say towards the center of a town and the whole town gets the exact same FM signal because they are trying to listen to the same song or the same broadcast at the same time. However, the mobile network covers the same city differently. A mobile network's coverage area is divided into what are called cells, the small areas which are called cells. That is where the name cellular communication or cellular network derives from. Because the area is covered into many different cells of small size and each of those individual cells is served by what is known as a base station. In proverbial terms, it is also known as the cell tower or simply the tower. Those are the same cell towers that you see all around us. Sometimes they are mounted a top a tall structure or sometimes they are just on the facades of residential or commercial buildings. But nonetheless, no matter what shape or form they take, in a cellular network, one tower or one base station is responsible for providing coverage to a limited geographical area that is called the cell. Different cells are designed in such a way that they have perfectly oscillating coverage.  Cellular networks are designed in an analogous manner to provide oscillating coverage and in most cases, if not all, no matter where you are, you are provided a cellular service from the nearest base station.First of all, we have shown a neatly hexagonal oscillating pattern as the shape of a cell. But in reality, that is not how cells look like. In reality, hardly any cell will ever have such a neat hexagonal pattern. Cells have somewhat different radiation and coverage pattern. However, we stick to this hexagonal pattern as the first step because it serves as a very powerful illustrative model of the concept of oscillation and the concept of cellularization. Once we have this basic concept in mind at a theoretical level, with the help of these hexagons, we can translate that understanding into real networks wherein cells tend to have slightly irregular shapes. But even though they have irregular shapes, network operators make sure that the entire geographical area is covered by at least one cell if not more than that. That said, in reality it is possible for certain small areas to lack cell coverage, which are proverbially also called coverage rules. For example, there is a base station over here. But if there is a building in the middle that is taller than the base station itself, then stands to reason that the signal from this base station may have a little difficulty reaching this point beyond a tall building. Or if there's a mountain or a hill, you can have a similar effect. In case of such obstructions, it is possible for certain points in a cellular network to be devoid of a cellular or wireless coverage and it is possible that if your phone goes into such an area that lacks sufficient wireless coverage, your phone can temporarily lose wireless service.The basic principle of modern cellular network design involves minimizing the number of dropped calls, while at the same time, maximizing the data rate that you get on your phone and the coverage area, while also limiting the number of towers that you have to build. I think we are all in agreement about these two points. That is, we have to minimize the number of dropped calls and maximize data rate and coverage area. You have to maximize the data rate and coverage area while keeping the number of base stations at a minimum.

#  > What Is A Cellular Network?

A regardless of the generation be it, 2G, 3G, 4G or 5G, which are the generations of cellular communications. the services that your phone is trying to access. Be it news, be it whether, be it email or be it video streaming, be it picture sharing or be it video telephone, etc. Whatever those services are, those services are present at the other end of the connection. And in between is what we proverbially call the cellular network that is deployed by your cellular network operator. Now, a cellular network has two fundamental components, one is called RAN or Radio Access Network, the second is called Core Network. Let's try to understand those one at a time. The RAN comprises multiple base stations or cell towers and these are the entities as we have seen that exchange wireless signals with your phone. So when your phone powers up and tries to send wireless signals somewhere, a base station that is nearest to your fourth is the entity that ultimately receives those wireless transmissions.

And as I also mentioned at a given point in time, you will be served by the base station that is closest to you. But when you move you may be handed off from one base station to another. And for that purpose two things have to happen, your network operator has to have a nationwide deployment of such base stations. And secondly those base stations have to be interconnected to each other directly or indirectly so that they can communicate with each other. So that they can ensure that your handover will be successful when you move from one base station to another.  A typical network operator in order to provide nationwide coverage might end up deploying literally tens of thousands of base stations. So all those base stations comprise what is known as the RAN or Radio Access Network. And those are the cell towers or the base stations for example, go to a cellular network operator store and purchase a subscription you get the same card. The network operator assigns you certain credentials. Are those credentials stored with every base station? No, not really, those credentials are stored in a central repository that is a part of the second half of the cellular network that is called the core network. So core network is the central repository where the data regarding your subscription etc will be stored. And apart from that, core network has another important functionality in that it is supposed to be the routing bridge between your phone and the services network over here.your services network doesn't know where you are located or what base station you are being served by. And that is where Core Network steps in, it acts as the middleman between your phone and the services network. That way, when the email server in the services network sends your individual email package to you, they first land on the Core Network. Core Network forward those email package to the precise base station that is serving you at that point in time. And that base station sends you those email package over your wireless channel, so this is how cellular communication works into it.


## 2 MODULE: WHAT IS 5G AND WHY WE NEED IT?

# > Evolution of Wireless Technologies

Cellular communications, as we know today, really started in the 1970s and '80s with what is radioactively now known as the first generation of cellular communications, i.e 1G. The predominant use case at that time was to enable people to make and receive voice calls on the go wherever they were. That's why the hallmark application of the first generation of cellular networks was voice. Now you will see a little qualifier there, see analog voice. In the first generation of cellular communications, our analog voice was imposed onto the outgoing carrier wave using analog modulation. Because our analog voice was transmitted over the air using analog modulation, that is the reason why you see the qualifier there as analog voice. First-generation of cellular networks is really where everything started in the 1970s and 1980s. Then came the second generation of cellular technologies, are proverbially known as 2G, sometime in the '90s.But in the second generation of cellular communication, the modulation technique that would be used to super-impose our voice onto the outgoing carrier wave would be digital modulation. In that modulator, in your phone, would convert your analog voice into a digital stream of bits and bytes, essentially a sequence of ones and zeros, and that sequence of ones and zeros are other than your analog voice, would be used to modulate an outgoing carrier wave.Not only can you compress and encrypt or encode a digital stream better than you can in analog stream, but other quality with which you can reproduce and transmit digital sound happens to be better than the quantity that analog voice can offer. That is a fundamental reason why other electronic ecosystem as a whole moved from analog voice to digital voice. But nonetheless, for second generation of cellular communication, our voice continued to be the predominant use case although text messaging had started to be popular by that time. That brought us to the third generation of cellular communication, also known as 3G, sometime in the first decade of this century. That is the first generation wherein we had seamless access to mobile Internet. For the first time, we had seamless access to all the resources available on the Internet.The speeds were somewhat limited compared to what we have today on the order of few 100 Kbps or a few Mbps. But suffice it to say that those speeds were more than sufficient to cover all the use cases that we had at that time. But the fundamental benefit of bringing internet connection to all the mobile phones was that it ultimately led to the invention of smartphones, which led to the advent of the next generation of cellular communications that is 4G, also known as LTE. Now, LTE made a few changes to the fundamental network architecture, which gave us some extraordinary benefits. Not only did it magnify the available data rates, from a few Mbps to a few 100 Mbps and then more than one gigabits per second, but it also greatly expanded the mobile ecosystem from just cell phones to other devices that had started cropping up at that time. 4G not only improved the speeds that it would offer to your mobile phones, but it also greatly expanded the Ecosystem beyond just everyday phones into the realm of tablets, smart home device, fitness trackers, etc. That was the fundamental power of 4G in that it expanded our ecosystem. Thankfully, that trend of ecosystem expansion has continued till date in that more and more devices of different varieties are asking network connectivity more reliably. Not only that, they are expecting higher and higher speeds and lower and lower lag from the network that they connect to. Given that the ecosystem has been expanding at a rapid clip. That brings us to ask one fundamental question. Is 4G or any legacy technology for that matter, truly sufficient to meet the requirements, not just for today, but continue meeting those requirements tomorrow and beyond? Is 4G truly sufficient? Is it a future-proof technology or is it going to be not sufficient beyond a certain point? Which will bring us to think about the next generation of cellular technologies, which will be called 5G. Let's try to answer that fundamental question whether there are any use cases or applications that 4G, cannot satisfactorily meet or cannot meet at all.

# > Why Do We Need Something Beyond 4G?

Given that work is becoming mobile and truly remote and people expect to be able to work from anywhere, no matter where they are. for example, high speed train, even if they are moving at 100 or 200 miles an hour, they will expect for high speed broadband like connectivity to be available on their mobile devices, even though they are moving at high speed on themselves, and that puts yet another dimension of pressure on existing ecosystems. The flip side of remote or ubiquitous work is that people will expect to have access to cloud computing no matter where they are. Maybe they are waiting for their flight at an airport, or maybe they are sitting in the lobby of their office building. But as more and more work is moving to the cloud, you need a reliable and high speed, high bandwidth, low latency conduct between your device and the cloud infrastructure, on which your device stores and retrieves all the data from. So the expectation that people will be able to work from anywhere is underscored in the fact that connected cloud computing is taking up more and more amount of wireless resources these days. Not to mention that immersive rich experiences like virtual reality or augmented reality requires significant data rates themselves. But not only that, along with the data rate, they also need extremely low latency and extremely high reliability because even one or two data packets in the virtual reality stream getting lost could be the difference between superb user experience and mediocre user experience.

And finally, we all see the advent of connected vehicles all around us. Vehicles are significantly smarter and more autonomous today than they were just ten years ago, let alone 15 or 20 years ago. And not only does the connected vehicle entail that you will be able to stream a movie for entertainment purposes, but it also entails that the vehicle, which is getting more and more software oriented, will be able to download software updates on the go map updates, for example, for navigation purposes. But not only that, more importantly, as vehicles become more autonomous, they will be able to communicate with other vehicles in their vicinity. And that communication, because it is so time critical, will require the underlying networks to provide a communication on a millisecond or even a microsecond basis.
how can we summarize those into a few points of a mission statement, so to speak, that will be applicable for the next technology should we determine it is indeed necessary? So some of the requirements could be distilled into these points here in that the up and coming applications of today and tomorrow require ultra high speeds and ultra high network capacity. Not only that, many of them will absolutely require low lag or low time delay so that they can offer real-time and interactive experience to their users, like VR or augmented reality. Furthermore, it wouldn't be very difficult, for example, to invent a different technology and build different networks for each of these individualized purposes. But the true power of this or any other technology would be to be able to serve all of these use cases and applications under the umbrella of just one common network or one common framework. And the broader mission statement for any technology of the future would be to not just connect individual people, but connect everyone and everything, i.e. not just connect all the people to each other, but connect all their devices that they use to other devices as well. And as it turns out, none of the legacy technologies, be it LTE or be it Wi-Fi, were designed to keep all these stringent requirements in mind. They weren't designed to meet the stringent requirements of these up and coming use cases. And that tells us that in order to not just meet, but significantly exceed the expectations of these cutting edge up and coming applications of today, tomorrow and beyond, we need a technology that goes beyond 4G or Wi-Fi. And that is the advent and justification for the next generation of cellular technology that is 5G, which is the technology that is going to be truly essential for next generation mobile experiences. And now that we have seen why we need a new technology beyond 4G. Let's look at some of the high level technological promises that this new technology 5G makes.

# > 5G NR: New Levels of Capability and Efficiency

So 5G also known as NR or new radio, the acronyms are interchangeable. So 5G NR is expected to provide us with unprecedented levels of capability and efficiency. The improvements that 5G promises to make on top of legacy technologies aren't linear but they are on the orders of magnitude in that. Those improvements aren't just like 10% or 20% better than before, but they are seriously 10 x or 50 x or 100 times better than what existed before. 5G will offer us significantly higher speeds or data rates also known as throughput as we know by now. 5G will offer a significantly higher data rates than existing technologies.those speeds are comparable to what we can get on a wired fiber connection or sometimes even beyond those fiber like speeds. So that would entail multi gigabits per second peak rates for download which is consumption and upload which is sharing data on the uplink. So fiber-like speeds which are an order of magnitude higher than existing technologies is the first USP of coming technology that is 5G. Another way to look at it is that of latency, latency is a technical name for packet delay, meaning that if you try to send one data packet from the transmitter to the receiver or any point in between. What is the time that it takes for the packet to go from point A to point B. That time delay in technical parlance is known as latency. And 5G's target is to significantly reduce the latency that it takes for the packet to go from one point to another. One of the headline offering is that 5G can help support end to end latency is that are as low as one milliseconds which is 1000 of one second significantly lower than the blink of a human eye. they allow us to not just provide this unprecedented level of performance to some users, but to the extent possible, uniformly over the entire network. So reliability of performance, not just the peak level of performance Is of interest in the fundamental 5G design as well. 5G continues with the same trend and it offers a lower cost-per-bit as compared to any of the legacy technologies. That will help network operators offer high limit or essentially no limit, unlimited data plans to more and more consumers at more and more affordable prices. So these are some of the headline improvements that 5G makes with respect to speed, latency, reliability and uniformity of performance and the cost-per-bit that is relevant to network operators. And if you have to put a number on our claim, some of the initial requirements that have been put forth for 5G include a 10x expectation of throughput improvement. About 10x expectation in the reduction of end to end latency, meaning that if your latency earlier was ten seconds for example, 5G is expected to cut that by a factor of 10 to one second. Not just that connection density is also expected to go up given that we won't just utilize phones to communicate with the network. But all the devices that exist around us will also try to communicate with the 5G network. The density of devices that are trying to connect to the network in a given area that is also going to significantly increase on the order of 10x as compared to what it does today. Spectral efficiency also needs to improve and the initial target is a threefold improvement and efficiency with which those devices will be able to utilize their frequency spectrum. And with all these improvements in place, 5G will be able to offer 100x improvement in the total traffic volume that the networks can handle. So these are some of the improvements that 5G promises to make and these are the orders of magnitude by which 5G will try to improve things on top of the Legacy Technologies.

# > 5G NR Service Classes Overview

this 10x, improvement in through ports 10x reduction in latency. service classes, it is a broad umbrella of services and all the applications or use cases that underlie the umbrella, happen to share some of the common requirements or characteristics. So consider service classes as umbrellas of applications or use cases, each of which shares some commonalities with other applications under the same umbrella. There are three main service classes in 5G. First up is "eMBB" or enhanced mobile broadband. It is essentially further high speed internet. The second one is "mMTC" or massive machine type communications, also known as mIoT or massive IOT. And the third one is "URLLC", ultra reliable, low latency communications. And now that we have seen, what are some of the high level promises that 5G makes, what kind of improvements people are expecting from 5G and what kind of service classes 5G is going to offer.

# > Enhanced Mobile Broadband (eMBB)

eMBB at such or any other service class titles aren't applications by themselves, they are rather service classes in that they are the umbrella under which specific applications can reside, applications that share certain common traits among them. What is the fundamental tenet of eMBB, which stands for enhanced mobile broadband? As the name suggests, eMBB is further high-speed Internet, speeds that are tenfold higher than those offered by the legacy technologies. eMBB clearly is on higher speeds and spectral efficiency because as we know, higher spectral efficiency contributes ultimately to higher speeds.Applications like Cloud computing, real-time video streaming, or real-time multiplayer gaming, or HD telephoning, whatever applications require significantly higher throughput or data rate. Those are the prime candidates for eMBB and that's why the emphasis is on improving speeds and spectral efficiency. On the other hand, some of the resource-oriented metrics such as bandwidth and power usage take a backseat. Not that bandwidth and power usage are completely ignored in here maybe no, they are optimized to a certain extent as well. But the priority emphasis is on maximizing data speeds and spectral efficiency even if it means that you consume a little more bandwidth and a little more power than you would otherwise.The cell towers that we see all around us on tops of buildings or on facades of buildings, they are the proverbial macrocells or macro base stations because they cover an area that is few square kilometers or such. So the radius of the cell would be equivalent of a few hundred meters or even more than a kilometer. Because they cover the network on a broader or a macro basis, they are called macrocells whereas small cells, as the name suggests, are responsible for covering only a small subset of the network area.

# > Massive Machine-Type Communications (m-MTC)

The next service class is that of MMTC or massive machine type communications. Also alternatively known as mIoT or massive IOT.fitness tracker, smart home devices, garage door openers and apart from that many other industrial devices such as sensors, industrial camera, industrial robotic vehicles, etc. All those devices which otherwise wouldn't connect to a network under the umbrella of mMTC, those devices will now also be provided with reliable network connectivity regardless of where they are, whether they are in the home or whether they are in an industry. So the basic tenet of mMTC is to connect not just people but they're worlds in that connect not just their phones and tablets, but also connect with each other. The devices that as human beings are surrounded by on a daily basis. Even if we may not be aware of the existence of the device. mMTC is the umbrella that enables such electronic devices to communicate with the network and enter with each other. "IOT" internet of things that is essentially your devices communicating with each other. And once you scale that paradigm on a massive stage like one million devices in a given area, that is what leads us to the paradigm of massive IOT also known as mMTC, or massive machine type communication.

Now, the fact that those million devices could be located anywhere and not just in our hands, tells us that at least some of those devices may be located far away from the nearest base station. Or they may be located in challenging coverage conditions. For example, look at your utility meter, that utility meter is likely going to be in a narrow alleyway between two houses. Or imagine fire sensor that has deployed somewhere deep inside a forest in order to detect and alert us about any wildfires. You cannot reasonably expect that those devices can have really pristine channel conditions simply because of the operating conditions that they're deployed in. The corollary of that fact is that nor can you expect anybody to go to the forest every week and recharge or change the batteries on the fire sensor that you have dropped in there. And that would indicate that that fire sensor would have to operate on the same battery supply for days or weeks or months or even years on it. And that requires us to fundamentally rethink our protocol design to make those protocols more power conservative rather than aggressive in terms of data transmissions. And that plays out well because most of these mMTC devices won't have significant data requirements. Imagine your utility meter, once again, what kind of data it would need to transmit just like what my IOT is, what time of the day it is and what is my current electrical readings? That data doesn't require more than a few mbps of throughput. However, it does require a reliable connection, no matter how challenging the coverage conditions get. And that is the reason why the fundamental emphasis of mMTC is on power conservation and simplicity of protocols instead of spirit or spectral efficiency. And given that protocols have been simplified, the mMTC devices in general tend to be very simple and low cost as compared to the devices we are used to visualizing for eMBB, such as phones or tablets.

# > Ultra Reliable Low Latency Communications (URLLC)

URLLC is an umbrella that encompasses all the applications and use cases that require a highly reliable but at the same time low latency communication link.an application of URLLC beyond mission critical services as well. In general, wherever low latency and high reliability would significantly improve the user experience or the safety of the user, that is where you are sick and potentially be deployed. as the name suggests, emphasis is on minimizing end to end latency instead of emphasizing higher speeds. Now, if some of the algorithms that minimize latency also happened to increase speed well and good, but the point is speed is not the first priority for some of these use cases. Minimizing latency is priority number one. And an equally important priority as latency is "improving reliability and availability". Reliability should be easier to understand, how reliable your system is. As far as both reliability and availability are concerned, 5G URLLC is in a position to offer extremely reliable and available performance on the order of five nines or six nines. Now once again not every application will require the identical degree of latency, reliability and availability, another corollary of URLLC is that given that the candidates for such service would be mobile in most cases." 5G has made some of the substantial improvements that help 5G promise not just significantly higher data rates and network capacity as required for mMBB, but also offer significantly higher connection density as required by mMTC. And at the same time offer significantly lower latency and significantly higher reliability than before as may be required for URLLC."

## 3 MODULES:5G NETWORK AND FEATURE 

# > 5G Network Terminology & Concepts

5G is at a high level and what are some of the fundamental promises that it makes with respect to performance. A services network where in all the services that your phone leverages such as email, web browsing, video streaming, etc. Those services are hosted in the services network now, although the general schematic is very similar in 5G. There are certain changes in that there are some specific network components and furthermore, some of the network components are given different names. For example, what we call the phone in five years technical parlance is called a U.E. or user equipment equipment that is ultimately operated by end users like you and I. That equipment is the user equipment. Data network as you may have guessed, is the place that hosts your email server, your video servers etc. All the services that are ultimately used by the phone which we now know is called UE technical parlance. And what lies in the middle is the proverbial 5G cellular networks. As you know, it has two parts, one is the access network Called 5G RAN and the other is the core network in this parlance called the next generation core or NGC. Focusing on the RAN as you know, the RAN is what has the wireless channel with your phone. And in technical parlance, the wireless channel is also called the air interface. Now the principal component of a 5G RAN is called a gnode-B." base stations in 3G were called node-B base stations in 4G Were an enhanced version of the node-Bs and hence they were called in or Enode-Bs. And the base stations in 5G are the next generation of node-Bs in that succession. And that's why they are called the gNode-B". Now, as you know, at a given point in time UE is served by a given gNode-B typically the gNode-B it is located the closest to and as the UE moves from one point to another, as the user handling the UE moves. Then the 5G connection would be transferred, so to speak from one gNode-B to another in a process reminiscent of what we have learned earlier. It's called handover and to make a handover possible. You can also guess that these gNode-Bs would have to be interconnected to each other. So that is what gNode-Bs do as far as the wireless channel or the air interface is concerned. They are the wireless end of the 5G network at the other end. As you can see all the gNode-Bs are connected the 5G core network. But you see a couple of interesting lines here and those are for a reason you see one daughter line going from each gNode-B. And then you see one solid line and there is a reason for which there are two lines. General traffic in a cellular network is typically broadly classified into two categories. Data and control as the legend shows here now. Although the names are technical, it is easy to understand the essence of those ideas in general. Whatever that you see on the screen of your phone, be it a picture, be it an email, be it a webpage, be it a streaming video. Whatever you generally see on the screen of your phone as the user oriented content is in technical parlance known as user data or user plane. Okay, whereas the signaling that occurs in the background under the hood, so to speak, in order to bring that data from a data network to your phone. Once again be it a picture or an email, whatever signaling that it takes for the network to bring the picture or the email from data network to your phone is called control messaging or simply signaling. So there are two types of packages that are exchanged in the typical cellular network data is what you see on the screen of your phone. Whereas control messaging or signaling would be the part that is used to establish and manage the session that actually brings the content to you out from the data network. core network and these lines is that the dotted lines go to a component called the AMF and the solid lines go to a component called use user plane function. What is AMF, it is access and mobility management function as the note says here. And the name is pretty self explanatory whenever your phone needs to access the network for a given service, it needs permission so to speak from AMF and once AMF has permitted the to access the network. The data session is established and managed by SMF which stands for session management function. Once again name is self explanatory. So session management function has responsibilities like bringing up your session, assigning your phone and IP address and managing and ultimately tearing down your session and the actual data. The actual content you see on your screen, be it a picture or an email that is handled by user plane function. And in this context, the name, once again maybe self explanatory because this network function handles user data whatever you see on your screen. That is called user plane function and that is the ultimate reason why you will see user plane function has data connectivity with the services network or the data network. So your picture goes from the data network to your UPF from UPF to your serving gNode-B and from your serving gNode- B or the wireless channel careful as always.

# > Network Architecture Options for 5G NR

 standalone or SA network or non-standalone or NSA network. What is a standalone 5G network? Well, at one end you have a 5G phone which connects to a 5G gNodeB, which itself is a part of a wider 5G RAN, and the 5G RAN connects to a 5G core network also known as 5G C. So end-to-end, it is a 5G system. And because that end-to-end 5G system is capable of standing on its own, so to speak, that is the reason why this particular option of 5G network deployment is called a standalone option.Whereas what they have today is a 4G core network, 4G LTE RAN, and all EUs. then the operator, as we can tell, has to make a few key changes in that the operator would have to upgrade its core network from 4G to 5G. And even though it sounds easy on paper, it is quite difficult to do in the reality. It takes a few quarters worth of planning and a significant amount of budget for any operator to upgrade its core network from one generation to another. it is going to take some planning and some budget.to go from 4G to 5G, operator has to upgrade the hardware and software on all of those base stations from 4G to 5G. But not only that, not only are the costs related to hardware and software, but keep in mind that in order for the RAN to operate in 5G technology, you have to have some 5G spectrum associated with that RAN. And that is where the NSA network step in. NSA, as you know, stands for non-standalone option. We will shortly see why it is called so. In a typical innocent network, operators can continue working with the existing 4G deployment. So operators who have 4G core network, which is called evolved packet core, will continue operating with that, and that 4G core network will connect with the nationwide deployment of 4G RAN. An NSA option allows you to have only a limited or surgical deployment of 5G gNodeBs in areas where you have severe capacity challenges which cannot be met by LTE. Now, once you have both 4G and 5G base stations in that area, something remarkable happens, you have a wireless coverage from two different technologies present in the same area. You have 4G signal coming in from the 4G base station and 5G signal coming in from the gNodeB. And that's where enters a special breed of modern phones which are called dual connectivity capable phones. They are called so because they are capable of connecting with two technologies at the same time, hence the name dual connectivity. A dual connectivity or DC capable phone can have a wireless channel with LTE base station. And at the same time it can have an independent parallel wireless channel with the 5G base station and those wireless channels will be LTE and 5G respectively. And because that phone has two wireless channels instead of one, the instantaneous throughput that the phone can leverage will be substantially higher than the throughput that an LTE or UE can obtain. And thus by increasing the instantaneous throughput or data rate or speed that is available to a given phone. You cannot have a nationwide deployment of 5G base stations under non-standalone options. Or even if you don't, you can continue operating your 5G network at least in those select areas. And because in this parlance, the 5G technology cannot stand on its own, there is no end-to-end 5G connectivity. That's why it is called a non-standalone option. 5G connectivity is limited to the wireless channel wherein 5G protocols will continue to operate. But remarkably, this 5G base station in the background will communicate with a 4G core network, not a 5G core network. And that is what I mean by a lack of end-to-end 5G connectivity, although there is no end-to-end 5G connectivity here. So NSA is only a stepping stone, a temporary solution. Long term solution is standalone option. And now that we have a good idea about not only the 5G network architecture, but also some of the deployment options. 
 
# > 5G Techniques Overview

At this point, we have seen some of the fundamental and ambitious promises that 5G makes with respect to performance in terms of data rate, latency, connection density, etc. But what are some of the factors that actually help 5G keep those promises is something we haven't seen, and that is precisely what we are going to do. Now, in all fairness, there are several features that help 5G in different ways keep different promises it has made. Discussing those features in their operational details tends to get pretty involved and it requires broader engineering background. But that is not the aim of today's class, and that's why we have done two things here: We have focused only on some of the principal techniques that provide some of the most significant improvements in 5G performance. Secondly, rather than going into the technical details, we are going to help you understand those techniques or the essence thereof in terms of some everyday easy to understand analogies that are framed in terms of our transportation cars and rules. What are some of the fundamental techniques we are going to talk about that help 5G keep some of the ambitious promises it has made? We will be talking about something called flexible slot-based framework. We will also talk about scalable OFDM-based air interface. We will talk about advanced channel coding, then about massive MIMO, and then about millimeter wave. It helps to mention that millimeter wave and massive MIMO happen to be so important that we have dedicated independent modules in this class to discuss those two concepts in further detail. But in this module, we will at least try to get a brief overview of what they are. With that in mind, let's get started with the first technique, that is flexible slot-based framework.

# > Flexible Slot-Based Framework

A flexible slot-based framework, as the name might suggest to some of you, is about making timelines a little flexible. 5G network is smart enough to allocate the remaining resources at runtime to other users so that those resources will not be wasted and because they'll be utilized by other users, the overall network performance will be better than before. Flexible slot-based framework at a high level is about carefully utilizing your resources and making certain changes at runtime in order to significantly improve your operational efficiency.In that, flexible slot-based framework is about carefully allocating the resources to different UEs and their applications depending upon their real-time requirement and that helps us avoid unnecessary wastage of resources. In that terms, flexible slot-based framework.

# > Scalable OFDM-Based Air Interface

OFDM stands for "orthogonal frequency division multiplexing". We have previously seen there are two types of channels: Wideband and narrowband. Imagine, for example, to improve the performance of your wireless system, you design your wireless system so that it can operate on a wideband channel. But then two questions arise; What if your wireless system is deployed in a spectrum where wideband channels are not available? On the other hand, even if wideband channels may be available, what if the application that is running on top of your wireless device doesn't require a wideband channel, what if it only requires narrowband channel? Or for any other variety of reasons, what if the network for a momentary instance doesn't have wideband resources for you to operate on? If you have designed your wireless system to be able to only operate on a wideband channel like this, then although the peak performance of your system maybe good, there are many situations wherein such design maybe sub-optimal and best, and that is where the essence of OFDM comes into picture in that by using its engineering magic, OFDM allows you to send data not on wideband channels, but rather on multiple narrowband channels. Keep in mind, in total you will have used a similar amount of bandwidth, but you will have used that in terms of different chunks are different modules. For example, if at a certain instant the network was able to give you the entire wideband channel, well and good. You can for example, utilize all four narrowband channels. But if the network did not have enough resources for you, if it could only give you half the bandwidth, in a wideband only design you wouldn't be able to operate. Whereas in an OFDM based design, which is flexible and modular in this context, that design can still help you operate by using the first two narrowband channels because only that bandwidth is available. This is among others, one of the principal benefits of OFDM in that it makes the wireless channel related operation of a system fully modular so that depending upon the resource availability or application requirements the system can determine in real time what is the amount of bandwidth that can be most profitably used and the system can precisely use that bandwidth because the operation has been modularized. 

# > Advanced Channel Coding

In module 1, we saw that there are several impediments that a wireless signal faces, for example, pathloss, noise, interference. A principle effect of those impediments is that they change the nature of the wireless signal so that by the time the signal reaches the receiver, it looks slightly or sometimes substantially different from the intended wireless signal sent by the transmitter and at such, it becomes somewhat or significantly difficult for the receiver to decode that wireless signal and demodulate or extract the intended data from the carrier wave. Is there a way to limit the effect of such impediments on the outgoing wireless signal? Indeed there is. That protection mechanism, so to speak, is called channel coding, or in communication parlance, it is also known as error control coding or forward error correction code just so you know." Channel coding at a high level is about taking your intended data that the transmitter has in mind and wrapping it up, so to speak, in additional metadata. That way, even if some of that data gets corrupted because of noise interference and pathloss, by looking at the metadata and the original data together, the receiver can make some educated guess about what the original data might have been". If the channel coding algorithms are designed and implemented correctly, it is possible that in most cases the receivers educated guess will be correct and the receiver will be able to decode and demodulate the data even in presence of noise and interference. 
# > Massive MIMO

MIMO stands for "multiple input, multiple output".We have mentioned that the transmitter will have an antenna and the receiver will have an antenna. The wireless signal travels between the transmitter and the receiver. Now this is okay, it will work. However, nothing says that you have to be limited on either transmitter or receiver with just one antenna. What if both the transmitter and the receiver had one more antenna that was working in parallel. So let's say this would be your transmit antenna one, and this would be your transmit antenna two. Its signal might look something different and it will reach receiver antenna two. So instead of sending just one wireless signal between two devices, you are now trying to send to different wireless signals between the same pair of devices. And if you do it carefully, it stands to reason that because those two wireless signals will carry a different data, you will have essentially doubled your data rate or output or your speed because some of the data will be carried on this wireless signal. Whereas at the same time, because you have an additional pair of transmit and receive antennas, you will be able to send a parallel a wireless signal carrying a different set of data. And that is what will significantly improve your data rate or speed or to put. And that is the fundamental premise of MIMO or multiple input, multiple output. Input in this context is the number of antennas on the transmitters and output in this context is the number of antennas on the receiver. So if both the transmitter and the receiver, multiple antennas, the multiple input multiple output, it is said to be a MIMO system. And the fundamental benefit of a MIMO system is that if you implement and design it carefully, it will help you significantly improve your data rate. Because instead of being limited to just one wireless signals between a transmitter and a receiver pair, you'll be able to send many more wireless signals at the same time. How many more? Well, that is the premise of massive MIMO, massive MIMO as you may have guessed at this point is just MIMO that is implemented on a more massive scale. What says that you have to be limited to two antennas, what if you had 10 antennas, 50 Antennas, 100, 200 or 500 antennas on your transmitter and receiver. You could potentially have 100,200 or even 500 data streams at least in theory to simplify things. So MIMO when it is implemented on a massive scale that is called massive MIMO."MIMO allows two different signals to be sent on the same channel at the same time without them interfering with each other because those signals are encoded differently". And they speak different language in simple terms. And if you got at least a high level just of this discussion, you will be able to probably connect the dots. That because you are sending more data using the same frequency channel, you have suddenly improved the spectral efficiency of your system, a metric that we also learned about earlier. So not just high throughput, but higher spectral efficiency is the second. And I would argue perhaps the more important benefit of MIMO or by extension massive MIMO. So this is the fundamental concept of what MIMO is and with that in mind. 

# > Mobile mmWave (Millimeter Wave)

This brings us to the next technique we are going to talk about, that is mobile millimeter wave. For a millimeter wave capability technology would be able to operate in such high-frequency bands where abundant bandwidth is available, you can solve one of the most fundamental problems that plays communication systems of today. Which is scale setting of frequency spectrum because you have abundant unused frequency spectrum in the millimeter wave frequency range. Any technology such as 5G as we will see later when it uses millimeter waveband, it can leverage a channel bandwidth that are as wide as 400 or 800 megahertz and significantly higher bandwidth ultimately gives you significantly high throughput and significantly higher network capacity as compared to the legacy technologies.Millimeter wave is about improving your technological capabilities and prowess so that you are now able to utilize some of the frequency spectra that were earlier unused and because they are unused, you will have access to abundant bandwidth in those frequency ranges on the order of 400 or 800 megahertz at a time. That enormous bandwidth directly translates to significantly higher individual user speeds and in aggregate manner, significantly higher network capacity. That is the fundamental premise of mobile millimeter wave and that is another reason why millimeter wave is a buzzword that is catching a lot of traction in 5G universe these days.

# > 5G Network Principles & Features Overview

There are other features and improvements as well that are adopted by 5G networks that make 5G networks, in general, more flexible, scalable, and that indirectly also ties in to some tangible performance improvements. The first principle is independence of software from hardware. Legacy technologies, be it 4G or Wi-Fi. Most network components are an integrated box, that box is designed and implemented to perform a specific functionality and that box comes with its own hardware and software. Imagine a Wi-Fi router that we all have at home, you just buy that router and it comes with its built-in hardware and software. That kind of integration is okay for a simpler system like Wi-Fi, but as networks get more sophisticated and use cases and service classes expand and become more aggressive, it turn so that that model of tight software and hardware integration doesn't work very well. Imagine a very familiar example. Imagine your cell phones from maybe 15 years ago before the advent of the smartphone, you would have the software and hardware of the phone coming from the same vendor, and imagine how limited the functionality was. On the other hand, imagine the smartphones of today, wherein the hardware on the phone comes from one manufacturer and applications that run on top of the smartphones come from a variety of different software developers or vendors. Imagine how flexible and how versatile the smartphone ecosystem is as compared to the legacy cellphone ecosystem, wherein there was tight integration of software and hardware. This is one small and simple example of what separation of software and hardware can buy you; it is, among other things, flexibility of operation and deployment and with flexibility comes scalability and efficiency of operation. Another point of separation or decoupling is that of between compute and storage resources. Compute resources are the network servers that are responsible for performing high-power computations, for example, encryption, authentication, user management, etc., whereas storage is anything that stores data for the long-term; if your laptop break up then you had all your data backed up on a cloud somewhere. What you can do is just borrow another laptop, access your cloud repository or Internet and download all your data from the cloud and start working on that new laptop as if nothing happened. This is the power of separating compute and storage resources, compute resource meaning your laptop, and in this case, storage resource, meaning your cloud. It gives you protection from real-time failures that are bound to occur in any real networks and by doing so, it offers your system some unprecedented amount of resiliency that otherwise wouldn't be possible. The third point is about separation of user plane and control plane. It is application data, what you see on your phone whereas control plane is under the hood background signaling that goes on in order to set up a user plane data session. For the reasons that are very similar to the couple of points that I made earlier, separation of user plane and control plane also has its undeniable and unprecedented benefits. All of these points, as we will see shortly, ultimately lead to the 5G design be cloud-compatible, in that, up to current cellular generations, operators have mostly deployed all the core network functionalities on dedicated server boxes and those servers are resided on the operator premises.5G design cloud-compatible and with cloud deployment come all the benefits with respect to flexibility, ease of deployment, scalability, and cost-effectiveness.

# > Network Slicing

In traditional technologies such as lt your core network components, how many ever they maybe were treated more or less as one homogeneous black box. If you had to serve more users or different applications, you will simply pick up a few additional resources from that homogeneous black box. And you will facilitate that additional service or additional users. So in terms of 5G if we went with that homogeneous approach, so to speak, then as always. If you focus on AMF, SMF and UPF you would have just a homogeneous box containing all these components. And you would simply assign those components for different users or different purposes. However, this homogeneous approach doesn't work very well when our applications or use cases are becoming as diverse and as aggressive as they are becoming in 5G. we have eMBB, we have massive IOT, we have URLLC all with desperately different requirements with respect to support latency and connection density. And as it turns out that serving such disparate applications or service classes using this homogeneous network approach isn't optimal anymore and I can give you a couple of examples reasons as to why. For example, if a certain group of components, let's say a few AMFs go down, then you don't know what service was using those AMFs. Because you had allocated them in a homogeneous manner or a black box manner. So chances are all the services that your network was offering, let's say IoT or URLLC or eMBB those services will be affected. And that would ultimately mean that some of the stringent requirements of those services will not be met. So that is one reason why this homogeneous approach doesn't make sense anymore. Another reason is that for example, as you know, eMBB would require a lot of user plane resources whereas IOT for example would require very few user plane resources. But because it would handle millions of devices in a square kilometer, it would require many more SMFs and AMFs as compared to UPF. So applications have widely different requirements and hence they are also going to require widely different amount and types of resources inside the core network. So these are a couple of salient reasons for which this homogeneous black box approach of allocating network resources doesn't work or isn't optimal anymore in 5G terminologies. That is where network slicing makes its entrance. What is a network slice? Well, network slice is a subset of the available network components that can provide an end to end service. So instead of this homogeneous network wherein resources are just a bundle altogether. Imagine you had those resources logically partitioned to different services precisely depending upon their individual needs. Keep in mind that every slice so to speak will contain at least one instance of every network components so that you can promise this intelligence service. But beyond that you can customize the deployment of a slice precisely depending upon the needs of the application you are going to serve. For example, as I mentioned, IoT will require more SMFs than UPFs. So the network slice or the logical subset of the network components that you have a portion for providing IOT service. You can have that slice contain many more SMFs than UPFs at the other end of the spectrum for an eMBB slice where emphasis is on throughput. You can have many more UPFs as compared to SMFs or AMFs and by separating the resources logically at least into different slices, you will have made sure that. You will have the ability to precisely meet all the aggressive and diverse requirements of different applications. And this will allow you to serve different applications within the confines of the same broader network but by creating logical subsets of different network components. Precisely depending upon the news of the applications that they are ultimately going to serve. So the second problem that I mentioned about the black box or homogeneous networking is already solved here. The first problem about component false, so to speak. So for example, let's say that in this new example your AMF related to IoT service goes down sure, a part of your IoT service will be affected. But because that IMF was responsible only for IoT service, you're URLLC and eMBB service can continue operating as if nothing happened. So you have isolated the points of failure and thereby you have contained any possible failures to a single service rather than those failures. Magnifying and percolating across different services of your network as the otherwise would homogeneous or black box network approach. So those are some of the benefits of network slicing in that not only can you allocate resources in a slice precisely depending upon the needs of the application or service class, it is going to serve. Which is the first point here, but resource isolation among services allows you to contain your possible failures to a limited number of services, letting all the other services operate without any problems. Not only that, it allows you as a network operator, it allows you to offer flexible subscription model. For example, what if there is a certain company that only wants its devices subscription to IoT like services. Then at a more reasonable and affordable price, you can give that customer access only to the IoT slice. On the other hand, if there is another customer that needs access to eMBB resources, you can sell that customer only for the eMBB sliced subscription. And the users of those customers will not interfere with your other slices. So flexible subscription model is another commercial benefit of network slicing.

# > SDN and NFV

Let's now try to understand a couple of related networking principles, software-defined networking, and network functions virtualization. Software-defined networking as the name suggests is about making your network more software-oriented than they were before. In that are trying to implement as many functionalities in a software and not just that, trying to implement them in generic software that could be compatible between different vendors. Currently, the way a cellular ecosystem works is that although the technology is similar, software and hardware choices of different vendors sometimes tend to diverge from each other and you tend to run into interoperability or compatibility problems between different vendors. One way, if not, the only way to solve that problem is to make your networks more software-oriented and implement that app and non-software in generic constructs rather than some vendor-specific constructs. Once you have your functionalities implemented in generic software, you can leverage a few important benefits. There are many, but some of those are listed here. For example, it might allow you to separate the control functionality from the actual device that is running. The functionality that is control of a device can be separated from the device itself. Once you aggregate control of all the devices into a few limited number of devices that can be looked at in a centralized location. Then you have essentially enabled your network to be a distributed system, which has its own set of benefits. With software-defined networking at a high level, the same underlying infrastructure because it is more software-oriented can be abstracted for different applications and network services. Not only does it make your system more resilient in that backward compatibility and interoperability is less of a problem and because you can have many different application or software developers working on that generic networking software, you also can benefit from rapid innovation in the entire ecosystem on account of the programmability that is offered by making these networks software-oriented. Another benefit of software-defined networking is what is technically called network function virtualization. But there is a simpler way to understand that. Now up to 4G part of our Wi-Fi technology, you have the networking software which is dedicated running on some certain dedicated hardware. Those hardware servers are hosted on these cellular network operators' premises. Case in point, if you have a home Wi-Fi system, you have to have that Wi-Fi access point under Internet model, look at it on-premise, you can't have them elsewhere. But although that work okay for legacy technologies, now that we are trying to upscale our technology offering into different service classes. This on-premise model doesn't turn out to be very flexible or very scalable. What is one solution to that? Well, let's go back to software-defined networking. Once you have all your networking functionalities implemented as generic and broadly compatible software, that generic software can run on top of generic or as they call it COGS, commercial off-the-shelf hardware so you don't have to have any specialized hardware anymore either. Because you are networking functionalities at least in the coordinate work, can run on generalized hardware. You as a network operator, don't have to buy any specialized hardware anymore. Normally you have to host that specialized hardware or a server firm, which turns out to be in the real networks. You don't have to host that server firm on your premise anymore as a network operator. You can safely outsource that deployment or offload it onto a Cloud network. For example, if you have AMFs running in the Cloud and you want one more AMF, all you need to do as a network operator is request your Cloud provider to download the AMF software at runtime on one or more additional a server, boot up that server, commission that and that server will, although it'll recite in the Cloud, will now be able to act as an additional AMF. The big advantage of making it into a Cloud is that you have instant scalability. Not only that, once you're traffic demands subsides and additional AMF if you had a commission is no longer necessary, you can simply ask your Cloud provider to decommission that machine and as such, you as a network operator will be charged only for the time for which that AMF machine was actively being used. That leads to certain cost efficiency as well for the network operator because having this deployment of the coordinate work not on their own premise, where they would need to invest a lot, they can have that deployment somewhere in the Cloud hosted by a third party. Because the network operator can commission and decommission resources in real-time precisely depending upon the network demand, the network operators can not only scale instantaneously but also impart a certain degree of cost-effectiveness of their network operation. That is not actually the end of the benefits of network function virtualization but here is another benefit. For example, here are multiple devices that are operating in a network. By definition, they don't care whether the AMF or SMF that they're talking to is located on operator premises or located somewhere else in the Internet domain i.e. on the Cloud as long as they get served by an instance of AMF with correct protocols, it doesn't matter to the end devices system whether that AMF resided on the premises or it resided in the Cloud. Because this cloudification, so to speak, is completely transparent with the end devices, as long as you maintain the performance guarantees between the 5G network and your Cloud providers' network, you should be able to provide reliable end-to-end 5G service without hosting a coordinate work yourself because your coordinate work is now sitting somewhere in the Cloud. That is the fundamental Internet of network function virtualization.

# > Mobile Edge Computing (MEC) 

 Edge computing, also known as mobile edge computing or MEC. In order to understand Edge computing, we have to take a step back and understand how the current ecosystem works. Let's say that you are leveraging a real-time service such as high-definition video streaming or real-time multiplayer Cloud gaming. Let's say that the UI is located here in a 5G network. Traditionally, the gaming or the video server resides somewhere in the Internet domain, which is far beyond the domain of the 5G network operator. Just to make a quick division, here is your 5G network, whereas here is a non-5G network, such as Internet. All the performance guarantees that we have seen so far through port latency connection density, they apply to the 5G portion of the network, not to the non-5G portion of the end-to-end communication link. Which means that if your 5G network operator spends a lot of time, money and resources, optimizing and deploying the 5G network to optimize performance. If the backhaul as it is called going from the 5G network to your video or gaming server in the Internet. If that backhaul is unoptimized, then your endpoint performance is only as good as your weakest link. That weakest link would be your Internet backhaul. In that case, even though the operator painstakingly deployed and optimized the 5G network, you as the end-user, won't see a phenomenal improvement and end-to-end performance. Because your performance with your bottleneck are limited by this weakest link, which is completely beyond your 5G network operators and domain. It is in the control of Internet service providers. Is there a better way of doing it? Is there a way we can still guarantee performance improvements to the user while using 5G network? Well, there is, and that is where Edge computing comes into picture. Imagine, instead of your video or gaming server residing in the Internet domain, what if you could bring that server into the domain of your 5G operator's network. Let's say somewhere here or somewhere here, or even somewhere close to the access network. Because you are bringing the application server from the wild western unreliable domain of Internet into a reliable, trusted domain of your operator's cellular network, or rather to the edge of other cellular network, so to speak. That is the reason why this paradigm is called Edge computing. If you got the hang of it, you would have no difficulty understanding some of the apparent benefits of Edge computing in that because your application server now resides over here. There is no unreliable hop for your data packets to traverse. Because the application server resides in the operator domain, the network operator can carefully optimize the performance of data packets between the access network and a core network as well as your gaming or video server. Because your video server is effectively now in your network operator's domain, end-to-end performance can be virtually guaranteed. At such even for third-party applications such as Cloud gaming or real-time video streaming, your end-to-end performance will be something like what 5G has promised. That is a fundamental premise of Edge computing, which is about bringing our different resources, be they computational, storage, or networking resources closer to the application devices and users running those or utilizing those resources. It is essentially shift of resources from centralized data centers that are located usually far away from the user and which are travels by at least one unreliable Internet hop which acts as the weakest link. By eliminating that weakest link and bringing that application server into the trusted and optimized domain of operator's 5G network, Edge computing can easily facilitate services that require extremely strict bounds on latency, that require enhanced security, as well as additional bandwidth.


## 4 MODULE: 5G SPECTRUM AND MM WAVE

# > The 5G NR Spectrum

We have previously learned that a millimeter wave is one of the fundamental techniques that 5G can use to remarkably improve its performance over legacy technologies. This is a quick summary look at the three principles frequency bands in which 5G as it is currently designed can operate. First of all, we have the proverbial low bands that are under 1 Gigahertz, also informally known as Sub-1 GHz. Some of the example bands in which 5G could be deployed here are bands like 600 MHz, 700, or 850 MHz, something such. Now we have seen previously in module one that as the frequency of operations increases the path loss or transmission loss that the wireless signal encounters also increases. Meaning that at a lower frequency path loss that the wireless signal undergoes will also be limited. And that is a one crucial reason why such low bands tend to be popular, not just with cellular services, but with many other communication services as well. The flipside of the coin is that because those bands are popular, there are many, many players contending for a little sliver in that frequency spectrum. And as such, the bandwidth that a certain occupant might get, for example, a certain network operator is pretty limited. Typically, it is maybe 10 to 15 MHz or maybe 20 MHz at the maximum. And that brings us to broaden horizon a little, because as we know, it's okay to have such a low bandwidth. But for truly significant performance improvement, we are also going to have to look at some of the broader channels. That is what brings us to the proverbial mid bands, also known in 5G parlance as sub-6 GHz, because these are the frequency bands under 6 GHz but above 1 GHz. The most prominent band or the frequency range in this spectrum is about 3.5 or 3.6 GHz, which is a part of the wider channel 3.4 to 3.8 GHz spectrum. Because this frequency spectrum offers us a wider channel bandwidth, we can think of this spectrum to deploy some of the 5G specific use cases or service classes, such as eMBB and mission-critical services. Typically, if not always, the amount of channel bandwidth available to a given cellular operator in this frequency range can be as high as 100 MHz, which is significantly higher than what was available somehow. And the third frequency band in which 5G can operate in under its current design, it's called millimeter wave. And it is the range of frequencies above 24 GHz. Most notably the frequency ranges, I should say that are currently picked for 5G's deployment are around 28 GHz and around 39 GHz. And in fact those happen to be the most prominent frequencies of 5G deployment in North American markets. In other markets such as European, or Chinese, or East Asian markets, some of the substance frequencies are also popular around 3.5 or 3.6 GHz. So, these are the three principal frequency bands in which 5G can be deployed. Now keep in mind that the 5G technology at such doesn't change dramatically depending upon what bands it is deployed in, some of the underlying principles and techniques remain applicable regardless of the bands. Although, depending upon the band of interest, there maybe some optimizations you can make along with the inherent advantages of those bands. That can give us significant performance improvement in 5G deployed in one frequency band as opposed to another frequency band. Although at the end of it, it is still the same 5G technology deployed in different band options.

 First is licensed spectrum, and it is called so because whoever wants to use that 5G spectrum has to have a specific license of usage, obtained from a local regulatory authorities, which in the US, as we discussed would be the FCC. So, because whoever has the license to operate in that band has exclusive access to that band, no one else can utilize that frequency band. Stands to reason that the performance that can be achieved in such bands tends to be remarkably good. So for example, if there is a certain cellular network operator that participated in a FCC auction and won the licensing rights to a certain frequency band, that cellular network operator would have the exclusive rights to use that band. It will be illegal for anyone else to transmit or receive in that band. And because that operator's customers are the only ones in utilizing that frequency spectrum, their performance would be better than otherwise. However, as it is an engineering problem, you can be sure that there are trade offs. In that, although performance is better and it's guaranteed in the licensed spectrum. The network operator also has to shell out a lot of money, millions of dollars, if not more, in order to purchase the exclusive usage rights to a certain frequency spectrum from the FCC. And ultimately, those costs get passed along to the consumers. And that is a chunk of what we pay our regular, a monthly cellphone bills for. At the other end of the rainbow, there is unlicensed spectrum, which is the exact opposite of licensed spectrum. In that this particular spectrum, it has been internationally agreed upon to be free for use for end consumers. You don't have to pay anybody any licensing or usage fees, if you want your device to operate in such an unlicensed spectrum. Think of your Wi-Fi router, or your bluetooth, or your garage door openers, your baby monitors, etcetera. There are plenty of wireless devices around us that we don't have to pay anybody usage or license fees for. And the fundamental reason behind that is because they operate in unlicensed spectrum, most notably around 2.4 GHz or around 5 GHz in frequency. And because it is unlicensed, it is free. So, you don't have to spend any money to buy or allocate spectrum. However, because the spectrum is free and many other people would be trying to use the same spectrum at the same time. 
 
# > Motivation & Challenges Behind mmWave Deployments

What after all is millimeter wave? Well, millimeter wave is nothing but a specific range along the frequency spectrum. It is that range where the wavelength of your radio or wireless signal is on the order of a few millimeters.it is roughly the frequency range above 24 GHz. That is when the wavelength of your wireless signal begins to go as small as a few millimeters. That is the reason why this frequency spectrum is called millimeter wave. 5G millimeter wave is nothing but when 5G is deployed in millimeter wave spectrum. it is underlying the same technology, 5G, just that there may be some improvements or optimizations possible on top of the principal technology. That is why 5G millimeter wave garners as much attention as we see it doing. Now, as I said, the principle operating frequencies for 5G millimeter wave are around 28 GHz and 39 GHz, which happen to be the most popular frequencies in North American cellular markets. But on an experimental basis, higher frequencies, such as a few [inaudible] above 52 GHz, are also being considered for some of the advanced uses of 5G. Here is a qualitative map of the 5G spectrum. Here are the sub six frequencies under 6 GHz and over 24 GHz would be some of the millimeter wave frequencies. Once again, sub-6 millimeter wave are merely two frequency bands in which the same technology, 5G, could be deployed. Now, why do we even consider a millimeter wave given that it is such a high frequency range and path loss is going to be remarkably high. Well, despite high path loss, there are certain undeniable advantages to millimeter wave. We will elaborate upon some of the technical advantages shortly. But the most fundamental advantage of millimeter wave is that currently millimeter wave is largely unused. Hardly any technologies that exist today have the capability to design, build, and operate hardware that can successfully function in those frequency ranges. Currently, only about satellite communication: Satellite radio, satellite TV, etc. Those are the systems in consumer domain that are capable of utilizing these frequency bands, but pretty much no other technology. Because those bands are not occupied by any other technology, ample amount of spectrum tends to be available in millimeter wave bands. As I mentioned earlier, you could have as much as 400 MHz or even 800 MHz of spectrum available for a single cellular network operator in millimeter wave frequency spectrum. This enormous bandwidth directly tells us that a millimeter wave has the foremost potential to meet the aggressive throughput requirements of the upcoming data hungry 5G applications. Think about eMBB use case on a count of 800 MHz bandwidth. Imagine the kind of throughput and network capacity your network will be able to achieve and that is the principle benefit for which we will venture into this uncharted territory of millimeter wave. First is something we have already discussed in that we know path loss is roughly proportional to the frequency of operation. Higher the frequency of operation in millimeter wave, it will mean that the path loss a millimeter wave wireless signal will encounter will be substantially higher.

However, beyond the most obvious one, there are a few other challenges as well. The second is listed here called building penetration loss, also known as BPL, as engineers call it. What is building penetration loss? Well, in most cases, are cell phone based stations or the gNodeB, as we'll call it in 5G, are located outdoors on top of the buildings or in open fields, where as many users may be located indoors. Maybe they are sitting in their offices, in their homes, shopping malls, restaurants, movie theaters, etc. Whenever a wireless signal from the base station has to reach that user, that wireless signal has to propagate through one or more walls of the building in which that user is located. As it happens, a lot of the wireless signals power can be dissipated, absorbed, or reflected by those intervening walls." It is possible that as much as 90 percent or even more of the energy of the wireless signal can be absorbed or dissipated in one or more of these buildings wall. That is nothing but building penetration loss." Because much of energy is dissipated while penetrating the building, so to speak, that's why deep indoor coverage becomes a challenge. Because building penetration loss is also a function of frequency, one can summarize that having a millimeter wave signal go from a base station outside to somewhere inside a building penetrating its thick brick or other walls is going to be challenging so providing deep indoor coverage is another obstacle in millimeter wave road. Another challenge and this is something that some of you may have experienced already, severe attenuation due to rain and foliage. Because of the way millimeter wave frequencies interact with humidity, water, and other elements in the atmosphere, elements such as rain, snow, moisture, or even tree foliage tend to absorb or dissipate much of the energy contained in a millimeter wave signal. Case in point, if some of you have satellite radio or satellite TV, compare how the service works on a bright and sunny day verses how the service works under a thick cover of cloud or worse yet, when it is raining or snowing heavily. You may have experienced that when it rains or snows heavily, your satellite radio or satellite TV services are interrupted. Even if you have some service, the quality of the service won't be very good. That is because satellite services operate in nearby bands as a millimeter wave and those frequencies tend to get severely attenuated because of rain and foliage. These are some of the fundamental challenges that millimeter wave signals face. But despite these challenges, there are several salient advantages because of which millimeter wave deployment becomes commercially viable

# > Advantages of mmWave (1/2)

the first of which is something we have already discussed in that because millimeter wave are largely unused so far, there are no other services are competing for spectrum in there. And at such, any service that can meaningfully utilize millimeter wave frequency spectrum can have access to large frequency bands and hence larger wide bandwidths and hence less crowding. And as we know by now, higher the bandwidth that is available to a service better will be its throughput capacity and other metrics of performance. And that is a clear advantage in terms of millimeter wave. The other three advantages tend to get a little technical understanding those in detail would require some technical background, but as always, we will try to abstract those details out and try to understand those concepts at a high level nonetheless. So let's try to look at what these bullets are saying. First one is saying more antennas leads to higher gain, why does it seem that millimeter wave can afford more antennas here is where a fundamental principle of radio frequency propagation comes into picture. At a high level, the principle says that the size of the antenna needed to work at a specific frequency is inversely proportional to that frequency, meaning that as your frequency of operation goes higher and higher, the size of the antenna that is needed to optimally send or receive signals and that wireless frequency begins to reduce and reduce. So if you compare two antennas, one is supposed to operate at a lower frequency and the other is supposed to operate at a higher frequency. The one corresponding to the lower frequency would be obviously bigger in size and the one supposed to be operating in higher frequency would be smaller in size. And because millimeter wave spectrum is significantly higher than our traditional frequency bands stands to reason that the antenna size in the millimeter of a bank, typically it tends to be very small as compared to the antenna size in traditional bands like one gigahertz or two gigahertz. So much so that an implementation can vary, but it should be possible for you to find a millimeter wave antenna that is smaller than a typical company. And because your individual antenna size is so small, it stands to reason that within a given physical space, let's say on the Ginobil. You can fit many more millimeter wave antennas as compared to antennas at any lower frequencies like one GHz for example. And that is the reason why this point says here that millimeter wave can utilize more antennas.A wireless signal is a form of energy. So indirectly every antenna is transmitting some energy outward. And if you have more antennas, more of them will be transmitting energy. And at such the Ginobili's if you imagine with these more antennas in aggregate will be transmitting more energy as compared to before, when it would have only a limited number of antennas. And because the Ginobil is now able to transmit more energy in technical terms, engineers call it higher gain. Of course, there are a few other connotations of the world again. But in this context and at our simplified level, this is what we need to understand that more antennas allow you to transmit many more wireless signals at a time and hence more wireless energy at a time does, leading to higher game.

# > Advantages of mmWave (2/2)

The last point is about higher Pathloss leading to better spatial reuse. That actually brings me to mention a slightly unrelated point in that sometimes the ingenuity of engineering design and implementation lies in utilizing some of the challenges and flipping them on their head to convert those challenges into advantages. If some of you practice martial arts, you will know that a fundamental tenet of multiple martial arts techniques is to use your opponent's momentum against themselves so as to gain an advantage in your fieldwork. Just like that, ingenious engineering design in millimeter-wave allows us to use some of the factors that would otherwise work against us to work in favor of us instead. Using higher Pathloss for better spatial reuse is actually  Without utilizing additional bandwidth just by taking advantage of the natural fact that at higher frequencies coverage is limited, you are able to deploy multiple cells at higher frequency within the same geographical area , and as such, you are able to boost the network capacity offered in that geographical area by N fold equivalent to the number of cells you're able to deploy. Such magnification of network throughput or capacity that is achieved by deploying more cells in the same area or packing the cells more densely is called cell densification. That is the third principle that gives us a significant advantage in terms of millimeter-wave. That is where higher Pathloss leads to better spatial reuse, meaning you could reuse the same space for multiple cells, i.e, fit many more cells, pack them densely, that is, network densification. Spatial reuse and network densification share this relationship. It is higher Pathloss and brilliantly taking advantage of that fact is what allows us and millimeter-wave deployments to densify the network and ultimately significantly improve not just the network capacity, but data speeds that are achievable by individual users. These are some of the fundamental advantages of millimeter-wave, namely a large bandwidth, more antennas leading to higher transmission gains. Some of those sophisticated algorithms which just FYI are called beamforming, but we'll learn about those later. Those beamforming algorithms allowing us high directivity, better focus, and hence higher spectral efficiency, and ultimately a higher Pathloss being used as an advantage rather than being discarded as a disadvantage in order to offer us better spatial reuse and ultimately, network densification which helps magnify user speeds and network capacity.

# > mmWave Deployment Opportunities Overview

At this point, we have seen some of the fundamental advantages that millimeter wave is poised to offer us from a technological perspective. Those are the advantages that make 5G millimeter wave deployments not just technologically or economically viable, but also commercially lucrative because they can open the doors to many other applications and services that we may not even have thought of before. That brings us to get some detailed understanding of some of the practical scenarios in which we can see millimeter wave networks. We have several examples coming up, but all those examples can be broadly classified, into two umbrellas, outdoor over here, and indoor deployments. Now, outdoor deployments is something that can intuitively make sense to us because most of the base stations that we see around us today are deployed outdoors, either on roofs of buildings or in an open field, etc. A cellular signal existing outdoors is a second nature to us by this point in time. But one might ask, what about the users who are located indoors? The rationale behind that question might be one small point we saw earlier about building penetration loss in that millimeter wave signal can lose maybe 90 percent or even more of its energy, when trying to penetrate through one or more walls of a building that may be made of bricks, plasters, etc. If a millimeter wave signal ends up losing 90 percent or more of its energy when going from outside of a building to inside can we really bank on millimeter wave to provide equivalent performance and all those improvements for indoor users as well? Well, the answer to that question is with some modifications, yes, we indeed can. That is where indoor deployments make their appearance. Now you might ask what are indoor deployments? Well, indoor deployments are where your base station along with the users, also exists at the same indoor facility where those users are going to use the network. But hold on a second. You might ask, how am I going to fit that humongous cell phone tower inside of a building or inside of a concert arena? Well, you don't have to fit the whole structure. 

There are two types of cells, as we had seen in module 2. There are macro cells that provide a citywide coverage, and then there are small cells that provide a coverage to smaller areas. Small cells, by definition, have only a subset of capabilities as macro cells and as such, they are significantly smaller in their size, their power requirements, as well as their footprints. When people think of indoor deployments, we are by default thinking about small cell deployments. Imagine a movie theater or an office building, a football stadium, concert arena, where your otherwise default option would be to bank on outdoor coverage, coming in with some bare bones, through port, and a latency offering. But with the advent of small cells, you can have a dedicated millimeter wave network inside your venue be it football stadium, enterprise building, etc. Just like you have cell phone towers outside of buildings currently, imagine you have miniature base stations known as small cells residing inside the buildings or inside those football stadiums or concert arena. Because those signals don't have to encounter building propagation loss anymore, virtually all the advantages that outdoor deployments had, the indoor users can leverage pretty much all the advantages using such small cell based indoor deployments. Such possibility of indoor deployments opens the doors to many other scenarios where cellular connectivity would otherwise be difficult or sometimes even unthinkable. But with the advent of small cells and indoor deployments, it is possible to provide an equivalent degree of performance, not just outdoors, but indoors as well which is anyways, where many users spend their time anyways. Now that we have understood the basic difference between outdoor and indoor deployments, let's try to look at some of the real life examples under both categories, wherein millimeter-wave could provide us some unique and promising benefits.

# > mmWave for Urban & Suburban Deployments

 First of those, is what is known as a dense urban deployment. a dense urban area is nothing but an urban area where there happens to be a high density of users higher than usual. Usual meaning, a suburban area, for example. Imagine or downtown, or a commercial area like neighborhood, wherein there are lots of tall buildings that are very close to each other, separated place, maybe by just a narrow lane. Each floor of the building is likely to have dozens or sometimes even 100 users, and many of them will be trying to ask for network resources for either upload or download of data. That is just one floor of one building, multiply that by all the buildings that you see in this typical dense urban downtown like scenario. As you can see, this is definitely a unique environment, not just with respect to it's data demand and density of it, but also with respect to propagation. Keep in mind that, hardly any user in such a dense urban deployment, is likely to have a proverbial line of sight or a direct visual line with that will be serving that unit. At such, most of the transmissions are going to be dependent on other phenomena like reflection or building penetration, and that is what makes this dense urban scenario very unique as compared to some of the other scenarios encountered in regular cellular networks. How can millimeter waves be beneficial here? Well, we know that millimeter wave by default is, anyways, going to have smaller coverage. So why expect just one cell to cover the entire downtown area? Why not densify the network here? First you want to the principles we learned about earlier. Why not deploy one cell here, another cell here, another cell here, et cetera? Why not deploy multiple cells in this limited area, densify the network so that each cell can offer throughput and coverage improvements to a limited area, but the area beyond that will be covered by another cell which will be deployed as a part of the whole densification plan. Because the enormous bandwidth, like four or 800 megahertz, along with all other millimeter wave benefits would be uniquely available, in each of those cells because they won't interfere with each other given that their coverage areas are different, because those advantages will be available in each of those densified cells, you can see that the throughput and capacity under each of these cells will be significantly higher as compared to a normal design, wherein, let's say you deploy LTE or rely on WiFi or just rely on one cell trying to cover the entire downtown. So by densifying cells in dense urban deployments, millimeter wave can bring us closer to wireless broadband in a more reliable manner. There is another use case that is applicable in such urban scenarios, be it a dense urban or even suburban, just for the sake of example.
 
We show a typical suburban area here wherein buildings are not so tall, and we are talking about what is known as a last mile solution. Now, what is a last mile solution?  Instead of building a hub over here and running individual wires to subscribers homes, the Internet service provider have built a 5G millimeter wave base station instead. So that millimeter wave base station, because it's signal is wireless, will be able to cover all the homes in it's coverage area. You don't need an individual wire to different homes anymore, you just need one millimeter wave base station, and how many of our homes are within the coverage area of that base station. That base station will be able to seamlessly send wireless signals to those homes. Now, imagine you are a new subscriber. Let's say you live somewhere here, and you are asking for a new service under this wireless paradigm. The wireless signal already reaches your home because you are within the coverage of the millimeter wave base station. So all you need to do as a subscriber is just call your ISP, buy the recommended piece of hardware, and if that piece of hardware is compatible with this millimeter wave signal, voila, you have a wireless broadband at your home facilitated by millimeter wave within a matter of minutes or maybe a couple hours, rather than having to wait for days or weeks. This is what is known as the last mile solution. The last mile between the ISP's hub and your home, and this is how millimeter wave technology is poised to provide wireless broadband on account of it's 400-800 megahertz bandwidth, along with other various advantages we have talked about.

# > mmWave for Rural Deployments

Rural areas tend to be plagued with their own set of challenges when it comes to providing broadband connectivity to individual homes. Fundamental reason is that homes in rural areas are typically separated far apart from each other. Your nearest neighbor could be as far as a quarter mile away from you. From an Internet service provider's viewpoint, it becomes not just expensive, but somewhat prohibitive to run individual cables from a local hub to those individual homes that are separated far apart. That's why rural areas don't garner much attention from established ISPs for economical reasons, and that is one prominent reason why rural areas have traditionally been underserved, and have lagged behind as far as a broadband Internet connectivity is concerned. Can millimeter wave in any way solve this challenge? Well, it definitely can. Imagine a rural area. An ISP would have to run miles long cables from the hub to individual homes, which would be prohibitive, as we mentioned. Imagine on the other hand, how a millimeter wave deployment would look like. Let's say instead of a hub, the ISP, or equivalently, a cellular network operator builds a millimeter wave base station atop a tall tower, so to speak, so that it has line of sight with the entire village. Once you have a millimeter wave base station atop a tall tower, it's millimeter wave signal can reach all these homes and all the other homes in this particular town as well. On account of it's large bandwidth and other benefits, you can see that this millimeter wave base station will be in a position to provide wireless broadband connectivity to all these homes, and all the advantages regarding flexibility and scalability continue to apply. For example, if you have a new home over here interested in getting wireless broadband service, no worries, the wireless signal already reaches that home, and all you need to do is subscribe to that service, buy the necessary hardware and voila, within a matter of an afternoon, you have wireless broadband connectivity to your home, something that would earlier take weeks or months, if at all, it were possible. So millimeter wave is not only beneficial in urban areas, but it has some practical use cases in rural areas as well. Given the recent emphasis from various global governments to bridge the connectivity gap between those who have broadband access versus those who don't, it can be easy to see how millimeter wave can narrow the gap between the connected and not connected by providing near instantaneous access to wireless broadband to rural communities that have traditionally been underserved. But as always, we're here to think critically. We earlier said that millimeter wave might have small network coverage by default. Then based on that, you would ask, hey, can a millimeter wave base station indeed travel beyond a few homes? Well, it is indeed possible for the millimeter wave signal to do so provided you configure your millimeter wave operation correctly.

a millimeter wave base station would have a wireless backhaul to the core network instead of a traditional wired backhaul. Trials are in progress to solve this problem as well. When we succeed, not if, but when we succeed, we will have had a truly wireless end-to-end broadband system facilitated by 5G millimeter wave.

# > mmWave for Fixed Wireless Access

At this point, we have talked a lot about how millimeter wave signals can be brought from G Norby to individual homes, essentially this part of the link from the base station to individual homes. We have talked a lot about that particular phenomenon in urban as well as rural scenarios and we have shown what are some of the concrete benefits. But one key question we have not yet answered is what will happen to the signal once it reaches an individual homes. Would all their devices in that home have to have 5G connectivity in order to leverage that millimeter wave capability? Well if they do well and good, but at least in the short term, the answer is not necessarily. And that is where a new type of device makes its entrance on the 5G ecosystem, and that it's called FWA or fixed wireless access device. In principle, if WA devices are very similar to the internet modem and WIFI router pair that many of us have in our homes but there are crucial differences. Let's see the similarities was. In that your modem is connected via a cable to your ISP sub your internet signal gets to your home over that wire and your modem and WIFI router put together translate that signal from the wired medium into a wireless medium. However, some of the disadvantages of that paradigm is that because your ISP's cable comes to your home at pretty much one designated point, your modem and router have to be a station at that point. If it is in your living room, we all know how ugly that arrangement looks. If it is for example in your basement or in your attic, you know that you will have coverage or signal propagation challenges and you will probably get a good spirit and some of the rooms but you will probably get poorer spirits in some of the rooms. 

Those are some of the disadvantages of the current cable internet environment. But contrast to that with a potential fixed wireless access device. This FWA device is truly wireless on both ends, it has no tether wire. On one end it will receive millimeter wave signals transmitted by the nearest G Norby. And at the other end all the devices in your home, be it your laptop, your phone, fitness trackers, you're smart appliances, smart home devices, whatever they may be, they will connect to this FWA device on the other end in a wireless manner. And that is what makes FWA truly portable. In that if you want better coverage in your living room, keep an FWA in your living room. If you want better coverage inside your home office or in your kitchen or in your bedroom, you can very well keep at those locations. Furthermore, you can buy more than one FWA as you want to unlike your current internet service wherein you are limited to one modem and one router. And you can strategically place those FWAs around the house so that your house has ubiquitous high speed connectivity that is ultimately facilitated by this G Norby. So once a wireless device in your home connects to the FWA, it has end to end connectivity with the G Norby that is facilitated by this FWA in a fully wireless manner. And FWA essentially, it ultimately brings wireless broadband facilitated by millimeter of devices to your home. And that is the fundamental reason why FWAs are catching more and more attraction when we look at this ecosystem of enabling wireless broadband access over 5G millimeter wave.

# > Indoor & Venue Deployments of mmWave

connection density of such venues, be it stadiums or concert or tends to be unprecedentedly high as compared to our usual suburban cellular networks. So that is one factor of differentiation. Another use case would be enterprises imagine office buildings. Office buildings are not only have dozens of users spread out across dozens of floors, meaning that there are unique propagation challenges to be encountered in such scenarios, but there is a variety of use cases that those office workers might be engaged in. Productivity tools such as email, instant messaging, database connectivity, videos of cats trying to chase laser pointers, all the tools that are essential for employee productivity, those can be seen being used to different extents by different employees. Not only that, beyond the essential throughput or latency requirements, you would have security requirements as well. For example, corporations offer and deal with sensitive data that needs to stay on site so that its security can be guaranteed. What are some of the possible alternatives that 5G has to offer in order to cover the same use cases under the same umbrella. 

As you know, airports and train stations are just full of display screens and notification boards, some of which are starting to go wireless. 5G millimeter wave a prime candidate for facilitating all these use cases at indoor deployments, intense event venues. Now, some of the challenges for millimeter wave that we saw earlier are not fortunately applicable for indoor deployments. The foremost challenge was building penetration loss and because as I mentioned, the venue specific millimeter wave network would be deployed inside the venue, you wouldn't have anything of walls for the signal to propagate through and that such building penetration loss is virtually eliminated altogether on account of the indoor deployment. Furthermore, because most indoor venues tend to be covered rain, snow or foliage attenuation is not going to be a factor at all. Furthermore, because these networks will be deployed in small cell manners, the distance that the wireless signal would have to cover in order to reach, the intended user would have to be substantially lower than the corresponding difference in a macro network for example. And that implies that path loss is not going to be a substantial factor in indoor deployments either, at least not as degrading as it is in macro networks. So indoor deployments have certain benefits, which render some of the fundamental disadvantages or challenges of millimeter wave mood and that is another technological reason that makes 5G millimeter wave a prime candidate in order to effectively meet the requirements of these futuristic use cases.

# 5 MODULE: MISSIVE MIMO 

# > Massive MIMO Definition & M-MIMO Antenna Arrays

Now that we have had a good understanding of what 5G millimeter wave is, let's turn our attention to another fundamental technique that we earlier learned that would provide significant benefits to 5G performance, and that is Massive MIMO. Although we have seen some of the initial fundamentals of Massive MIMO in Module 3, let's now try to take a deeper look. We'll learn about what Massive MIMO is, and what are some of its immediate benefits. We will first look at the conceptual angle of those benefits. Then as always, we'll try to give you some practical examples of what kind of benefits we can expect from realistic 5G deployments that can carefully leverage Massive MIMO. As we already know, Massive MIMO is MIMO that is deployed on a massive scale. That makes it an integral part of both 5G millimeter wave as well as Sub-6 deployments, although two slightly different degrees. Massive MIMO, also known as M-MIMO, in short-time, has essentially two sides of the same point in that there are certain prerequisites to Massive MIMO. If you deploy and implement those correctly, you'll get to reap certain enormous benefits of Massive MIMO. Let's first look at the prerequisites. Prerequisites, if you read the name carefully, Massive MIMO, may be somewhat understandable to you. That is, an antenna array is a fundamental prerequisite, and Massive MIMO, because it entails many more antenna, would require a panel with many individual antenna elements. That panel of multiple antenna elements, or simply called antennas, is quite an antenna array. Now, for 5G, Sub-6, or millimeter wave, each of those individual antennas is very small and that is because something we have seen earlier. The physical size of the antenna is roughly inversely proportional to the frequency of operation. High frequency of 5G operation makes those antennas smaller than those for legacy technologies. This is where the difference between Sub-6 and millimeter wave that I earlier alluded to also comes into picture in that because millimeter wave or frequencies of operation are significantly higher than those for Sub-6. Stands to reason that 5G millimeter wave antennas will be substantially smaller than the antennas that would be needed for 5G Sub-6. To summarize, an antenna array is a rectangular panel in most cases that fits many more antennas. For Sub-6, it might be on the order of, let's say, 10, 30, or 60 antennas, whereas, for millimeter wave, it could be easily on the order of 100, 250, or 500 antennas.

# > What Is Beamforming?

That brings us to the benefit that is facilitated by massive MIMO, and that is in technical terms known as beamforming.Then beamforming entails that those antenna elements will focus their transmitted energy as a sharp narrow beam focused only in other design direction of interest towards the user. Because there is this one sharp beam of energy, there is no wastage in lateral directions. So that is the fundamental premise of beamforming rather than sending your energy in all the directions wherein it may not be necessary, rather focus your energy as a sharp B only in the direction where it is necessary. If your user is located here, you will send your beam of energy precisely in this direction and not in the entire space. That is the fundamental premise of beamforming, a focusing transmitted signal only in the desired direction and thus leading to a narrow beam. This is something that we had also alluded to when discussing some of the fundamental benefits of millimeter-wave. We are going to not only talk more about beamforming and its advantages but we're also going to tie the two together as to what relationship millimeter-wave and a massive MIMO share. But for the time being, let's continue talking about the benefits of beamforming. Going back to this schematic, one of the fundamental benefits of beamforming can be explained as follows. Going back to Module 1, I hope you'll remember that we had talked about a specific metric of wireless systems, that is signal to noise ratio. This is your desired signal and denominator would be noise. We have also established that in order to improve the performance of a wireless system, it would help to maximize the signal to noise ratio, ie., for a given noise level, maximize the level at which the desired signal is received. As you may have already guessed, by avoiding wastage in lateral directions, by focusing your outward energy only in the direction where it is indeed useful by forming a sharp narrow focus to beam you can clearly see that beamforming improves the level of the desired signal at the receiver. Thereby, it improves the numerator of the ratio, and thereby it improves SNR. Improvement in SNR and thereby improvement in spectral efficiency, and thereby improvement in user speed or throughput is one of the fundamental benefits of beamforming. But that is not the end, there are a few more benefits, we are going to talk about, although this would be the most fundamental of the model.

# > Benefits of Beamforming

As it says here beamforming can enable us to generate multiple narrow beams. What it means is that if your user is located here then your energy beam will be transmitted in this direction. On the other hand, if your user is located somewhere here, you're transmitted beam would be oriented in this direction. So a typical 5G gNodeB is capable of forming multiple beams. Now whether those multiple beams can be formed at the same time or whether the gNodeB can form those multiple beams only at different points in time. That is a valid question and the answer to that usually depends on implementation. And overall sophistication of the software and hardware that goes in Antananarivo as well as being forming. So it depends on implementation but in general be it simultaneously or at different points in time. gNodeB's do have the ability to form multiple beings in different directions. So that no matter where the user is different directions can be covered by outward be himself energy. Now, given that multiple beams can be transmitted stands to reason that we would want to have different types of beams, so to speak. The beams that are generally formed along the horizontal plane are a part of what is known as as or horizontal beam forming. And the beams that are along the vertical axis are called elevation, beforming or vertical beforming. So as a mutual beforming as you can see is useful to cover all the users that are located along the ground plate. Whereas elevation beforming will be beneficial in covering different users that are still located on different floors of the same building. And by putting as immutable and elevation beforming together. We can have a truly three dimensional coverage by means of these individual narrow beams. So this is how beforming can provide you 3D coverage. And that brings us to the second benefit of massive mind. 

In that, as it says here, individual beams can serve different users. And that brings us back to what we mentioned over here, that depending upon the sophistication of the gNodeB. A certain gNodeB may be able to generate multiple beams at the same time. So if you are considering such a gNodeB that can form multiple beams at the same time. And you have another user over here, let's say this is user one and this would be your user two. Given that the gNodeB can form multiple beams at the same time, it can send one beam to user one. And at the same time it can use the antinori to form under the independent being that goes to user two at the same time. And because you are now able to serve both users one and two at the same time using different beams. You would have improved not just the individual throughput or data spirits of those users. But you would have improved the network capacity as well. And that in technical terms is called mu Mimo or multi user Mimo. Because you are able to serve multiple users in the same cell at the same time using different beams. That phenomenon is called mu Mimo and the throughput as well as the network capacity improvement brought on by a mu Mimo serves as the 2nd benefit of massive MIMO without beforming. Because without beforming, you cannot have mu Mimo. The benefit that is provided by improved snR versus reuse of the same frequency channel is independent additional benefits. And that is the beginning of the true power of beforming. In that it improves snR of wireless communication. Mu MIMO can greatly improve network capacity. And because different beams can use the same frequency channel. You can send more data within the same frequency spectrum for different users. Which significantly and additionally improves your spectral efficiency.

# > beamsweeping 

And beamforming in that the narrow beams of energy are capable of going farther and providing better signal quality. The second clause is something we have already seen in the form of improved SNR.In that if you have energy focused in a narrow beam because your energy is focused in just one direction, that beam of energy will go farther. Now, the technical significance of this is related to cellular coverage. We saw during the previous module that every cell has a coverage and it depends on its frequency of operation and it is the boundary where the signal from that cell begins to attenuate. But that coverage definition is mostly given in terms of legacy technologies without beamforming. But if you use beam forming as a 5G Norby, you are going to focus your energy in a certain direction and that allows the beam of energy to travel further, thus extending the reach of your wireless signal and thereby improving your cellular coverage. And in the same essence, beam sweeping is used to transmit not specialized information that may be relevant just one or two users. But rather beam sweeping is used to transmit generic information that will be useful and applicable to all the users no matter where they are located in the cell. Going back a few modules we learned about control plane versus user plane. User plane obviously is user specific but some elements of control plane is are relevant for all the users in the 5G cell, no matter where they are. And beam sweeping is used to transmit those generic pieces of control information that achieve fundamentally a couple of things. It helps the begin communicating with the 5G network. And on the other hand it helps the gNodeB roughly figure out in what direction the UE is located whether the UE is located here or whether the UE is located there. So that the subsequently informing can be based on that decision. So this is the overall concept of beeamforming which ultimately relies on massive MIMO. And the antenna array. And this is how individual beams can be used to perform beamsweeping.

# > Evolution of the Radio Access Network (RAN)

 We'll study the overall evolution of a cellular RAN that has brought us to the current generation, which is what 5G will most likely use. We will take a magnifying glass to that specific design and see what are some of the principles of RAN design followed by a 5G. No matter the generation, RAN basically has two components; they may be called differently in different generations of cellular communications, but their essence is pretty much the same, in that one can be called BBU or the baseband unit, and the other would be called RRH, or remote radio head, or simply RU, meaning the remote unit. Although generation-wise names are different, the essence is very similar. For us to understand what the two components of the RAN are as stated here, let's take a minute to understand what is a baseband, so to speak. In order to understand what BBU . Whereas the moment that signal gets converted into carrier or radio frequency, that is when we will be talking about the realm of radio unit or remote radio head. Everything above this point roughly would be a part of RU or RRH . Baseband once again is bits and bytes and associated data that you see on the phone and in the form that your phone handles it, that is called baseband, whereas once your baseband signal is converted into higher radio frequencies, that is when it begins to be in the realm of remote radio head or remote unit. 
 
 But then an optimization came along on top of this D-RAN or Distributed RAN that optimization being C-RAN or Centralized RAN. Over here, we still have the logical division between BBU and RRH, which will now be called RU, but essence is the same as RRH. But instead of having a one-to-one correspondence between BBU and RRH like the older generation, this generation allowed you to combine several BBUs into what is known as one single BBU pool, and that BBU pool would be responsible for handling multiple RUs. You would no longer need to have a dedicated BBU co-located with your base station, you could have one common BBUs across multiple base stations. The base station would still have the antennas, which would be a part of radio unit, but the backend BBU wouldn't necessarily be located with the base station, it would have been located at another place. However, one thing that stayed the same as the previous generation is that the connectivity between BBU and RRH, also known as the fronthaul as we are going to see shortly, that fronthaul has some very specific requirements with respect to the type of data that it is supposed to carry. Throughput and latency, reliability and availability on that specific fronthaul just like we have end-to-end throughput, latency, reliability, etc., metrics, 5G networks also have specific throughput, latency, and reliability metrics on this wire that goes from BBU to RU that is called for fronthaul. In both the generations, the fronthaul continue to have some stringent requirements because it carried essentially similar data between BBU and RU. However, that substantially changes in the current generation of radio access networks and that is known as vRAN or Virtualized RAN. Although this is not a mandate, 5G is well in a position to utilize this aspect of RAN design rather than some of the original older aspects. In this aspect, we still continue to have a BBU and a radio unit, but not only is that BBU pooled across multiple base stations, but that BBU pool itself can be offloaded into a cloud. Network operator wouldn't have to host this BBU pool on their own premise anymore just like we saw several network functionalities can be offloaded onto cloud in one of the earlier modules. This functionality, i.e. BBU, can also be safely offloaded to the cloud. 5G is increasingly getting in a position where it will follow this architecture wherein some of the BBU functionalities will be residing in the cloud rather than on operator premises. We continue to maintain this one-to-many correspondence between BBU and your radio units, just that your BBU now resides in a cloud and is able to handle requests from multiple radio units.

# > Motivation for RAN Virtualization

operators don't have to host the BBU by themselves anymore, they can save on CAPEX and OPEX because you can essentially commission and decommission a Cloud host on-demand depending upon your BBU pool traffic load. That gives your deployment a certain degree of scalability, flexibility, and cost-effectiveness. CAPEX and OPEX savings are paramount in RAN virtualization. Not only that because your BBU pool and radio unit are essentially two different entities now deployed at two different places, nothing stops you from buying your radio unit from one vendor and your BBU pool from another vendor, which were earlier be impossible because of the tight integration. Because 5G allows you to buy two things from two different vendors, that makes your networks not only more flexible but also better in terms of compatibility between different vendors. Any ecosystem that supports multiple vendors is naturally going to be more competitive and innovation is going to be more fruitful and faster in such an ecosystem as compared to an ecosystem that is dominated by one or two players. Time to market and flexibility of overall deployments are some of the other commercial benefits of RAN virtualization. But are there any engineering benefits? Yes, there absolutely are. We have seen before that especially in the millimeter-wave flavor of 5G, cell densification could be a prominent application that provides 5G benefit. If for example, in this legacy architecture, you had to densify your cell, you would have to buy not just BBU but RRH as well and that would be somewhat of an expense. But in this architecture, the only thing you need to buy as an operator is a Remote Radio unit, that's your new cell and that connects to your BBU connected to the Cloud. Because your Cloud-based BBU can scale pretty much seamlessly, you don't need to buy any additional resources, but you can simply leverage the inner scalability of the Cloud model and right there you have an additional cell leading to a densified paradigm. Virtualization is of paramount importance when we speak of cell densification especially in millimeter-wave. But there is another engineering advantage as well.

With new services that are popping up, such as virtual reality or augmented reality or extended reality as they're also called, some of them will predominantly rely on one of the other technologies we talked about, Mobile Edge computing. As you can see, one of the possible deployment options for Edge computing was that your Edge server could not only reside with your Core Network but it could also reside with your Radio Access Network. In modern parlance, if you could couple the deployment of your Edge server with your BBU somewhere in a Cloud, right there, you have opened doors on several other aspects of performance improvements, not just in terms of latency, but in terms of a traffic carriage capacity of the network operator along with reliability, availability, and user experience metrics that your end-user is going to experience. RAN virtualization is catching traction, not just because it has some commercial or economical benefits, but it is going to facilitate some of the features or techniques that 5G is going to rely on to improve performance such as cell densification and Mobile Edge computing. With these benefits of RAN virtualization in mind, let's take a magnifying glass to the latest generation of RAN deployments and see whether there are any other aspects of design we need to be aware of and what could be some of the practical ramifications of those aspects.

# > RAN Functional Split

At this point, we have known that are typical base station has two portions, BBU and radio unit, or RRH. Based band unit is responsible, as the name suggests for basement processing and remote radio head would be responsible for RF or radio frequency processing. The concept of layerization in cellular networks in a typical ran or base station or in this specific case based band unit. It's not a homogeneous black box, but rather there are multiple layers of responsibility within BBU each layer has a unique functionalities and responsibilities. And one of those responsibilities is to make certain decisions and pursuant to that decision, go on the behavior of all the bottom layers. That is one common functionality of all the multiple layers that exist within a BBU. And in logical terms it is no different from a typical corporation. How is a typical corporation structure? There is one headquarters where executives certain work. Then there are some more regional offices where in there are, let's say, upper management employees. Then middle management sits at a few more locations and add the bottom the staff and supervisors, they work at all the locations. So a typical corporation is like a pyramid. And as you go down that pyramid, the number of locations at which its members are present that goes up. But not only that there is a fundamental difference between those layers in that some of the real time data today short term decisions are made at the location at staff or supervisor level. Whereas as you go up the chain of command, the nature of decisions to be made also changes. The decisions that executives or upper management's made are mostly related to long term strategic operation of the company rather than day to day short term operation of the company. And if you have this corporation, a model in mind, you can look at the BBU in a similar manner. There are multiple layers of hierarchy within a BBU, lower layers are responsible for making short term real time decisions. Whereas upper layers are responsible more towards making long term strategic operational decisions. And just like your headquarters, executives or upper management don't need to be located at every single outlet of the company. Just like that some of the upper layers in the BBU don't have to be located at every single base station. Because they make long term strategic decisions that are applicable to not just one base station but could be applicable to multiple base stations. And that is where the layerization and functional split inside the RAN or BBU in specific comes into picture. In that the BBU in 5G can be logically divided into two components, one called centralized unit and the other called distributor unit. Centralist unit would be the equivalent of executives and upper management Inc responsible for making long term strategic decisions and hence they are located at select offices. Whereas distributed unit will be the equivalent of, let's say middle managers or staff and supervisors that are located at many more locations, preferably at every location. And they are mainly responsible for making real time, day to day operational decisions.

Given the relationship between the kind of decisions CU and DU make it is possible to split this BBU into two parts CU and DU. And once again going to the nature and urgency of their decisions DUs are present with nearly every radio unit. Whereas centralized units, as the name suggests are located only once every end number of DUs. So although there may be one to one correspondence between DU and radio units, there doesn't need to be one to one correspondence between CU and U. One CU can very comfortably handle multiple DUs just like one corporate headquarters is responsible for multiple regional offices. So this is how RAN functional split happens between CU and DU one CU corresponding to multiple DUs. And the reason that split is made is because our DUs are responsible for real time decisions. Whereas CUs are responsible for long term strategic decisions and hence they can be safely separated away. Furthermore you can have one CU handling multiple DUs and thereby giving you operational efficiencies. Not only that because you're CU can be located, it can also be deployed in a cloud, just like your some of your other network functions can, as we have seen before. And with cloud deployment come all the other benefits, such as scalability, flexibility and cost effectiveness. So this is what RAN functional split is, and these are some of the fundamental reasons why we even think about RAN functional split.

# > Traditional RAN vs. Virtualized RAN (vRAN)

Although, 5G is in a position to fully utilize virtualized RAN, it is not necessary that every network operator will go with virtualized RAN. There are certain use cases where traditional RAN can work fine enough if not better. For example, if you just had to provide bearable coverage in this particular area as an example, an operator could just buy a traditional RAN base station that would have both the baseband unit as well as the radio unit in an instant. You would have a sufficient wireless coverage in this area, thanks to this new cell. But there are certain use cases where traditional RAN ends up being an overkill. For example, as we know, RAN has two components; baseband unit and radio unit. It is possible for some use cases that you will only need coverage-related capabilities of radio unit, but not processing capabilities that come with baseband unit. Whereas, if you buy the entire box, then you have essentially spent your money on buying a BBU that wasn't exactly beneficial to you. This is one scenario, along with many others, wherein traditional RAN could end up being an overkill for your system. Although, such a deployment might sound simpler. One of the foremost drawbacks of traditional RAN, as you may have guessed already, is higher capital and operational expenditure. How would a virtualized deployment look like on the other hand? Well, the individual base stations would mostly just be the radio units antenna, and the associated remote radio heads or RF processing units, and all those radio units would ultimately connect to a BBU. The point here is that, the virtualized deployment is more flexible as compared to traditional deployment because all you need is a radio unit, which is going to be substantially cheaper than deploying an entire base station. For example, on this radio unit, you need higher computational power, you can scale your Cloud resources here accordingly, and dedicate that capacity to this particular radio unit so that, that particular 5G cell now is in a position to give higher throughput and higher capacity exactly as your design warranted. Virtualized RAN can essentially achieve the same or even better results, but at lower cost, thereby, requiring operators to have lower startup investments. But not only that, because of the overall Cloud-friendly nature of virtualized RAN, these deployments are more scalable and flexible than what a traditional RAN would entail. The prime benefit of virtualized RAN is that, it is a surgical solution, it solves only those problems that are currently critical, and by avoiding wastage of capital on problems that aren't really problems, by taking the surgical approach, virtualized RAN utilizes operator capital more efficiently, thereby, still giving the improved performance in terms of latency and throughput that the RAN is required to offer.



